{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "# define dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "       \n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import r2_score\n",
    "import re\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 5\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "import re\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test = pd.concat(CM_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test = pd.concat(CF_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']      \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "# Set up a dict with values to test for each parameter/argument in the model object\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "scoring = ['f1', 'recall', 'precision']\n",
    "\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "M_gm_cv = GridSearchCV(model, param_grid, scoring=scoring,\n",
    "                     cv=kfold,\n",
    "                     n_jobs=-1,\n",
    "                     random_seed = random_seed,\n",
    "                      verbose=2,\n",
    "                    refit='f1')\n",
    "F_gm_cv = GridSearchCV(model, param_grid, scoring=scoring,\n",
    "                     cv=kfold,\n",
    "                     n_jobs=-1,\n",
    "                     random_seed = random_seed,\n",
    "                      verbose=2,\n",
    "                    refit='f1')\n",
    "\n",
    "M_rc = M_gm_cv.fit(M_X_train_ready_selected,M_Y_train_ready)\n",
    "dump(M_rc, \"M_gam\\M_rc_fit_sample_data.joblib\")\n",
    "F_rc = F_gm_cv.fit(F_X_train_ready_selected,F_Y_train_ready)\n",
    "dump(F_rc, \"F_gam\\F_rc_fit_sample_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 19 and input n_features is 27 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb11a002d10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mCIR_best_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIR_RFT_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mMR_Y_train_selected_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR_RFT_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMR_X_train_ready_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;31m# MR_Y_train_selected_pred_thresh = (MR_xgb_selected.predict_proba(MR_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mIR_Y_train_selected_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIR_RFT_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIR_X_train_ready_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \"\"\"\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         result = self.predict_proba(X, raw_score, start_iteration, num_iteration,\n\u001b[0;32m--> 870\u001b[0;31m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \"\"\"\n\u001b[1;32m    922\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, start_iteration, num_iteration,\n\u001b[0;32m--> 923\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             warnings.warn(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                              \u001b[0;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                              % (self._n_features, n_features))\n\u001b[0m\u001b[1;32m    687\u001b[0m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[1;32m    688\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 19 and input n_features is 27 "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 5\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test_ready = pd.concat(CM_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test_ready = pd.concat(CF_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']         \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "\n",
    "\n",
    "M_RFT_selected = load(\"M_gam\\M_rc_fit_sample_data.joblib\")\n",
    "F_RFT_selected = load(\"F_gam\\F_rc_fit_sample_data.joblib\")\n",
    "CM_RFT_selected = load(\"M_gam\\M_rc_fit_sample_data.joblib\")\n",
    "CF_RFT_selected = load(\"F_gam\\F_rc_fit_sample_data.joblib\")\n",
    "\n",
    "M_best_index = M_RFT_selected.best_index_\n",
    "F_best_index = F_RFT_selected.best_index_\n",
    "CM_best_index = CM_RFT_selected.best_index_\n",
    "CF_best_index = CF_RFT_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_RFT_selected.predict(M_X_train_ready_selected)\n",
    "\n",
    "F_Y_train_selected_pred = F_RFT_selected.predict(F_X_train_ready_selected)\n",
    "\n",
    "print('Confusion matrix on the  M train dataset:', confusion_matrix(M_Y_train_ready, M_Y_train_selected_pred))\n",
    "print('Average F1 score on the  M train sample', \"{:.1%}\".format(M_RFT_selected.cv_results_['mean_test_f1'][M_best_index]))\n",
    "print('CI F1 score on the M train sample', \"{:.1%}\".format(2*M_RFT_selected.cv_results_['std_test_f1'][M_best_index]))\n",
    "print('Average Sensitivity on the M train sample', \"{:.1%}\".format(M_RFT_selected.cv_results_['mean_test_recall'][M_best_index]))\n",
    "print('CI Sensitivity on the M train sample', \"{:.1%}\".format(2*M_RFT_selected.cv_results_['std_test_recall'][M_best_index]))\n",
    "print('Average Positive Predictive Value on the M train sample', \"{:.1%}\".format(M_RFT_selected.cv_results_['mean_test_precision'][M_best_index]))\n",
    "print('CI Positive Predictive Value on the M train sample', \"{:.1%}\".format(2*M_RFT_selected.cv_results_['std_test_precision'][M_best_index]))\n",
    "print('Parameters', M_RFT_selected.best_estimator_)\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_ready, F_Y_train_selected_pred))\n",
    "print('Average F1 score on the F train sample', \"{:.1%}\".format(F_RFT_selected.cv_results_['mean_test_f1'][F_best_index]))\n",
    "print('CI F1 score on the F train sample', \"{:.1%}\".format(2*F_RFT_selected.cv_results_['std_test_f1'][F_best_index]))\n",
    "print('Average Sensitivity on the F train sample', \"{:.1%}\".format(F_RFT_selected.cv_results_['mean_test_recall'][F_best_index]))\n",
    "print('CI Sensitivity on the F train sample', \"{:.1%}\".format(2*F_RFT_selected.cv_results_['std_test_recall'][F_best_index]))\n",
    "print('Average Positive Predictive Value on the F train sample', \"{:.1%}\".format(F_RFT_selected.cv_results_['mean_test_precision'][F_best_index]))\n",
    "print('CI Positive Predictive Value on the F train sample', \"{:.1%}\".format(2*F_RFT_selected.cv_results_['std_test_precision'][F_best_index]))\n",
    "print('Parameters', F_RFT_selected.best_estimator_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "M_Y_test_selected_pred = M_RFT_selected.predict(M_X_test_ready_selected)\n",
    "F_Y_test_selected_pred = F_RFT_selected.predict(F_X_test_ready_selected)\n",
    "CM_Y_test_selected_pred = M_RFT_selected.predict(CM_test_ready_selected)\n",
    "CF_Y_test_selected_pred = F_RFT_selected.predict(CF_test_ready_selected)\n",
    "\n",
    "print('Confusion matrix on the M test dataset:', confusion_matrix(M_Y_test_ready, M_Y_test_selected_pred))\n",
    "print('F1 score on the M test dataset:', \"{:.1%}\".format(f1_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "print('Sensitivity on the M test dataset:', \"{:.1%}\".format(recall_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the M test dataset:', \"{:.1%}\".format(precision_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F test dataset:', confusion_matrix(F_Y_test_ready, F_Y_test_selected_pred))\n",
    "print('F1 score on the F test dataset:', \"{:.1%}\".format(f1_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Sensitivity on the F test dataset:', \"{:.1%}\".format(recall_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the F test dataset:', \"{:.1%}\".format(precision_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the CF  test dataset:', confusion_matrix(CF_Y_test_ready, CF_Y_test_selected_pred))\n",
    "print('F1 score on the CF test dataset:', \"{:.1%}\".format(f1_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "print('Sensitivity on the CF test dataset:', \"{:.1%}\".format(recall_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the CF test dataset:', \"{:.1%}\".format(precision_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the CM test dataset:', confusion_matrix(CM_Y_test_ready, CM_Y_test_selected_pred))\n",
    "print('F1 score on the CM test dataset:', \"{:.1%}\".format(f1_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "print('Sensitivity on the CM test dataset:', \"{:.1%}\".format(recall_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the CM test dataset:', \"{:.1%}\".format(precision_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "         dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "         dy_test_predict = model.predict(dx_test)\n",
    "         ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "         F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "         print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "         prevalence = np.sum(dy_test)/len(dy_test)\n",
    "         pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "         pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "         pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "         pyplot.xlabel('Sensitivity')\n",
    "         pyplot.ylabel('Positive Predicted Value')\n",
    "         pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "         pyplot.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "pr_f1_curve(M_RFT_selected, M_X_test_ready_selected, M_Y_test_ready)\n",
    "pr_f1_curve(F_RFT_selected, F_X_test_ready_selected, F_Y_test_ready)\n",
    "pr_f1_curve(CF_RFT_selected, CF_test_ready_selected, CF_Y_test_ready)\n",
    "pr_f1_curve(CM_RFT_selected, CM_test_ready_selected, CM_Y_test_ready)\n",
    "\n",
    "print('Confusion matrix on the M train dataset:', confusion_matrix(M_Y_train_ready, M_Y_train_selected_pred))\n",
    "print('F1 score on the train  M dataset:', \"{:.1%}\".format(f1_score(M_Y_train_ready, M_Y_train_selected_pred)))\n",
    "print('Sensitivity on the M train dataset:', \"{:.1%}\".format(recall_score(M_Y_train_ready, M_Y_train_selected_pred)))\n",
    "print('Positive Predictive Value on the M train dataset:', \"{:.1%}\".format(precision_score(M_Y_train_ready, M_Y_train_selected_pred)))\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_ready, F_Y_train_selected_pred))\n",
    "print('F1 score on the F train dataset:', \"{:.1%}\".format(f1_score(F_Y_train_ready, F_Y_train_selected_pred)))\n",
    "print('Sensitivity on the F train dataset:', \"{:.1%}\".format(recall_score(F_Y_train_ready, F_Y_train_selected_pred)))\n",
    "print('Positive Predictive Value on the F train dataset:', \"{:.1%}\".format(precision_score(F_Y_train_ready, F_Y_train_selected_pred)))\n",
    "\n",
    "pr_f1_curve(M_RFT_selected, M_X_train_ready_selected, M_Y_train_ready)\n",
    "pr_f1_curve(F_RFT_selected, F_X_train_ready_selected, F_Y_train_ready)\n",
    "# Explain model predictions using shapley value\n",
    "# M_explainer = shap.TreeExplainer(M_en1_selected.best_estimator_)\n",
    "# M_shap_values = M_explainer.shap_values(M_X_train_ready_selected)\n",
    "# F_explainer = shap.TreeExplainer(F_en1_selected.best_estimator_)\n",
    "# F_shap_values = F_explainer.shap_values(F_X_train_ready_selected)\n",
    "\n",
    "# CF_explainer = shap.TreeExplainer(CF_en1_selected.best_estimator_)\n",
    "# CF_shap_values = CF_explainer.shap_values(CF_test_ready_selected)\n",
    "\n",
    "# CM_explainer = shap.TreeExplainer(CM_en1_selected.best_estimator_)\n",
    "# CM_shap_values = CM_explainer.shap_values(CM_test_ready_selected)\n",
    "\n",
    "# Plot summary_plot\n",
    "# shap.summary_plot(M_shap_values, M_X_train_ready_selected, max_display=24)\n",
    "# shap.summary_plot(F_shap_values, F_X_train_ready_selected, max_display=29)\n",
    "\n",
    "# shap.summary_plot(CM_shap_values, CM_test_ready_selected, max_display=24)\n",
    "# shap.summary_plot(CF_shap_values, CF_test_ready_selected, max_display=29)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
