{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "# import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "random_seed = 10\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# load data\n",
    "phia_male = pickle.load(open(\"Transformed_data\\phia_male_step1.pkl\", 'rb'))\n",
    "phia_female = pickle.load(open(\"Transformed_data\\phia_female_step1.pkl\", 'rb'))\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.max.rows\", None)\n",
    "phia_male = pd.DataFrame(phia_male)\n",
    "phia_female = pd.DataFrame(phia_female)\n",
    "M = phia_male\n",
    "F = phia_female\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_C_D = pd.get_dummies(M, columns=['country'], prefix='Country')\n",
    "F_C_D = pd.get_dummies(F, columns=['country'], prefix='Country')\n",
    "\n",
    "# Rename country\n",
    "country_list = ['Tanzania', 'Malawi', 'Swaziland', 'Zambia']\n",
    "i = 0\n",
    "for colonne in list(M_C_D.columns):\n",
    "    if re.match('Country', colonne):\n",
    "        M_C_D.rename(columns={colonne: country_list[i]}, inplace=True)\n",
    "        i += 1\n",
    "\n",
    "country_list = ['Tanzania', 'Malawi', 'Swaziland', 'Zambia']\n",
    "i = 0\n",
    "for colonne in list(F_C_D.columns):\n",
    "    if re.match('Country', colonne):\n",
    "        F_C_D.rename(columns={colonne: country_list[i]}, inplace=True)\n",
    "        i += 1        \n",
    "\n",
    "M_C_D = M_C_D.astype(str).astype(float)\n",
    "F_C_D = F_C_D.astype(str).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # remove variables with very low variance \n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.01)\n",
    "constant_filter.fit(F_C_D)\n",
    "len(F_C_D.columns[constant_filter.get_support()])\n",
    "constant_columns = [column for column in F_C_D.columns if column not in F_C_D.columns[constant_filter.get_support()]]\n",
    "print(constant_columns)\n",
    "F_C_D.drop(labels=constant_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.01)\n",
    "constant_filter.fit(M_C_D)\n",
    "len(M_C_D.columns[constant_filter.get_support()])\n",
    "constant_columns = [column for column in M_C_D.columns if column not in M_C_D.columns[constant_filter.get_support()]]\n",
    "print(constant_columns)\n",
    "M_C_D.drop(labels=constant_columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_C_D.drop(columns='HIV status final', inplace=True)\n",
    "M_C_D.drop(columns='HIV status final', inplace=True)\n",
    "\n",
    "\n",
    "# M_correlation_matrix  \n",
    "M_correlated_features = set()\n",
    "F_correlated_features = set()\n",
    "M_correlation_matrix = M_C_D.corr()\n",
    "F_correlation_matrix = F_C_D.corr()\n",
    "# # remove columns for correlation above 0.8\n",
    "for i in range(len(M_correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(M_correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname =M_correlation_matrix.columns[i]\n",
    "            M_correlated_features.add(colname)\n",
    "len(M_correlated_features)\n",
    "\n",
    "for i in range(len(F_correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(F_correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname =F_correlation_matrix.columns[i]\n",
    "            F_correlated_features.add(colname)\n",
    "# len(F_correlated_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_C_D.drop(['90 with ARV data',\n",
    " 'ART Recode for 90-90-90 with ARV data',\n",
    " 'Aware for 90-90-90 with ARV data',\n",
    " 'Awareness combining self-report',\n",
    " 'Duration of time on ART',\n",
    " 'Ever tested HIV',\n",
    " 'LAg: recent or long term infection ARV results',\n",
    " 'Marital status',\n",
    " 'Self-Reported HIV Status of HIV',\n",
    " 'Tested HIV and receive results',\n",
    " 'Union type',\n",
    " 'Used condom at last sex in past 12 months',\n",
    " 'VFal load suppressed',\n",
    " 'Wealth index',\n",
    " 'Whether ARVs detected',\n",
    " 'age group',\n",
    " 'all past 12 months sex partners spouse or live-in',\n",
    " 'last sex partner spouse or live-in in last 12 months'],axis=1, inplace=True)\n",
    "F_C_D.drop(['90 with ARV data',\n",
    " 'ART Recode for 90-90-90 with ARV data',\n",
    " 'Age group',\n",
    " 'All past 12 months sex partners spouse or live-in',\n",
    " 'Aware for 90-90-90 with ARV data',\n",
    " 'Awareness combining self-report',\n",
    " 'Current marital status',\n",
    " 'Delivered 3 years preceeding survey',\n",
    " 'Duration of time on ART',\n",
    " 'Ever tested HIV',\n",
    " 'LAg: recent or long term infection ARV results',\n",
    " 'Last sex partner spouse or live-in in last 12 months',\n",
    " 'Pregnancy status',\n",
    " 'Self-Reported HIV Status of HIV',\n",
    " 'Self-reported HIV status during last pregnancy',\n",
    " 'Tested HIV and receive results',\n",
    " 'Union type',\n",
    " 'Used condom at last sex in past 12 months',\n",
    " 'VFal load suppressed',\n",
    " 'Wealth index','respondent is a mother'],axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne\n",
    "import pandas as pd\n",
    "columns =['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married or lived together',\n",
    "       'Avoiding pregnancy', 'CFcumcision status', 'Age at fFst sex',\n",
    "       'Ever sought TB treatment', 'Alcohol drink frequency',\n",
    "       'Urban area indicator', 'Known HIV status', 'Wealth quintile',\n",
    "       'HIV status final', 'Sexual intercourse in the past 12 months',\n",
    "       'Ever had sexual intercourse', 'Bought or sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent or long term infection', 'CD4 category', 'on ART',\n",
    "       'ART initiated past 12 months those ever on ART', 'Tanzania', 'Malawi',\n",
    "       'Swaziland', 'Zambia']\n",
    "categorical =['Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married or lived together',\n",
    "       'Avoiding pregnancy', 'CFcumcision status', \n",
    "       'Ever sought TB treatment', 'Alcohol drink frequency',\n",
    "       'Urban area indicator', 'Known HIV status', 'Wealth quintile',\n",
    "       'Sexual intercourse in the past 12 months',\n",
    "       'Ever had sexual intercourse', 'Bought or sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent or long term infection', 'CD4 category', 'on ART',\n",
    "       'ART initiated past 12 months those ever on ART', 'Tanzania', 'Malawi',\n",
    "       'Swaziland', 'Zambia']\n",
    "        \n",
    "# nonnormal = [''Age','Age at fFst sex',]\n",
    "\n",
    "groupby = 'HIV status final'\n",
    "maletable = TableOne(M_C_D,columns= columns,categorical=categorical,\n",
    "                   groupby =groupby,pval= False)\n",
    "\n",
    "print(maletable.tabulate(tablefmt=\"xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_C_D_col_names = M_C_D.columns.drop('HIV status final')\n",
    "F_C_D_col_names = F_C_D.columns.drop('HIV status final')\n",
    "CM_train = {}\n",
    "CM_Y_train = {}\n",
    "CM_test = {}\n",
    "CM_Y_test = {}\n",
    "\n",
    "for name in list(country_list):\n",
    "    CM_train[name] = M_C_D[M_C_D[name]!=1].astype('float')\n",
    "    CM_test[name] = M_C_D[M_C_D[name]==1].astype('float')\n",
    "    CM_Y_train[name] = M_C_D['HIV status final'][M_C_D[name]!=1].astype('float')\n",
    "    CM_Y_test[name] = M_C_D['HIV status final'][M_C_D[name]==1].astype('float')\n",
    "    CM_train[name].drop(columns='HIV status final', inplace=True)\n",
    "    CM_test[name].drop(columns='HIV status final', inplace=True)\n",
    "\n",
    "CF_train = {}\n",
    "CF_test = {}\n",
    "CF_Y_train = {}\n",
    "CF_Y_test = {}\n",
    "\n",
    "for name in list(country_list):\n",
    "    CF_train[name] = F_C_D[F_C_D[name]!=1].astype('float')\n",
    "    CF_test[name] = F_C_D[F_C_D[name]==1].astype('float')\n",
    "    CF_Y_train[name] = F_C_D['HIV status final'][F_C_D[name]!=1].astype('float')\n",
    "    CF_Y_test[name] = F_C_D['HIV status final'][F_C_D[name]==1].astype('float')\n",
    "    CF_train[name].drop(columns='HIV status final', inplace=True)\n",
    "    CF_test[name].drop(columns='HIV status final', inplace=True)\n",
    "    \n",
    "M_X_train_entFe = {}\n",
    "M_X_test_entFe = {}\n",
    "M_Y_train_entFe = {}\n",
    "M_Y_test_entFe = {}\n",
    "\n",
    "F_X_train_entFe = {}\n",
    "F_X_test_entFe = {}\n",
    "F_Y_train_entFe = {}\n",
    "F_Y_test_entFe = {}\n",
    "\n",
    "\n",
    "# split between train (80%) and test (20%) with stratification\n",
    "for name in list(country_list):  \n",
    "    M_X_train_entFe[name], M_X_test_entFe[name], M_Y_train_entFe[name],\n",
    "    M_Y_test[name] = train_test_split(CM_train[name], CM_Y_train[name], test_size=0.2, stratify=CM_Y_train[name],random_state=random_seed)\n",
    "    \n",
    "# split between train (80%) and test (20%) with stratification\n",
    "for name in list(country_list):  \n",
    "    F_X_train_entFe[name], F_X_test_entFe[name], F_Y_train_entFe[name],F_Y_test_entFe[name] = train_test_split(CF_train[name], CF_Y_train[name], test_size=0.2, stratify=CF_Y_train[name],random_state=random_seed)\n",
    "    \n",
    "# standardization of the data\n",
    "M_scaler = StandardScaler(with_mean=False)\n",
    "M_X_train_entFe = round(pd.DataFrame(M_scaler.fit_transform(M_X_train_entFe), columns=M_C_D_col_names), 2)\n",
    "M_X_test_entFe = round(pd.DataFrame(M_scaler.transform(M_X_test_entFe), columns=M_C_D_col_names), 2)\n",
    "M_var_entFe = M_scaler.var_\n",
    "\n",
    "# F_scaler = StandardScaler(with_mean=False)\n",
    "F_X_train_entFe = round(pd.DataFrame(F_scaler.fit_transform(F_X_train_entFe), columns=F_C_D_col_names), 2)\n",
    "F_X_test_entFe = round(pd.DataFrame(F_scaler.transform(F_X_test_entFe), columns=F_C_D_col_names), 2)\n",
    "F_var_entFe = F_scaler.var_\n",
    "\n",
    "f = open(\"pure_data\\M_X_train_entFe.pkl\", 'wb')\n",
    "pickle.dump(M_X_train_entFe, f)\n",
    "f = open(\"pure_data\\M_Y_train_entFe.pkl\", 'wb')\n",
    "pickle.dump(M_Y_train_entFe, f)\n",
    "f = open(\"pure_data\\M_X_test_entFe.pkl\", 'wb')\n",
    "pickle.dump(M_X_test_entFe, f)\n",
    "f = open(\"pure_data\\M_Y_test_entFe.pkl\", 'wb')\n",
    "pickle.dump(M_Y_test_entFe, f)\n",
    "\n",
    "f = open(\"pure_data\\F_X_train_entFe.pkl\", 'wb')\n",
    "pickle.dump(F_X_train_entFe, f)\n",
    "f = open(\"pure_data\\F_Y_train_entFe.pkl\", 'wb')\n",
    "pickle.dump(F_Y_train_entFe, f)\n",
    "\n",
    "f = open(\"pure_data\\F_X_test_entFe.pkl\", 'wb')\n",
    "pickle.dump(F_X_test_entFe, f)\n",
    "f = open(\"pure_data\\F_Y_test_entFe.pkl\", 'wb')\n",
    "pickle.dump(F_Y_test_entFe, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================================================================\n",
    "# subsampling 3 countries out of 4\n",
    "#================================================================================================================================\n",
    "\n",
    "CM_train = {}\n",
    "CM_test = {}\n",
    "CM_Y_train = {}\n",
    "CM_Y_test = {}\n",
    "\n",
    "for name in list(country_list):\n",
    "    CM_train[name] = M_C_D[M_C_D[name]!=1].astype('float')\n",
    "    CM_test[name] = M_C_D[M_C_D[name]==1].astype('float')\n",
    "    CM_Y_train[name] = M_C_D['HIV status final'][M_C_D[name]!=1].astype('float')\n",
    "    CM_Y_test[name] = M_C_D['HIV status final'][M_C_D[name]==1].astype('float')\n",
    "    CM_train[name].drop(columns='HIV status final', inplace=True)\n",
    "    CM_test[name].drop(columns='HIV status final', inplace=True)\n",
    "    \n",
    "    \n",
    "#================================================================================================================================\n",
    "# subsampling 3 countries out of 4\n",
    "#================================================================================================================================\n",
    "\n",
    "CF_train = {}\n",
    "CF_test = {}\n",
    "CF_Y_train = {}\n",
    "CF_Y_test = {}\n",
    "\n",
    "for name in list(country_list):\n",
    "    CF_train[name] = F_C_D[F_C_D[name]!=1].astype('float')\n",
    "    CF_test[name] = F_C_D[F_C_D[name]==1].astype('float')\n",
    "    CF_Y_train[name] = F_C_D['HIV status final'][F_C_D[name]!=1].astype('float')\n",
    "    CF_Y_test[name] = F_C_D['HIV status final'][F_C_D[name]==1].astype('float')\n",
    "    CF_train[name].drop(columns='HIV status final', inplace=True)\n",
    "    CF_test[name].drop(columns='HIV status final', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#================================================================================================================================\n",
    "# impute and standardize\n",
    "#================================================================================================================================\n",
    "\n",
    "M_X_train = {}\n",
    "M_X_test = {}\n",
    "M_Y_train = {}\n",
    "M_Y_test = {}\n",
    "\n",
    "F_X_train = {}\n",
    "F_X_test = {}\n",
    "F_Y_train = {}\n",
    "F_Y_test = {}\n",
    "\n",
    "\n",
    "# split between train (80%) and test (20%) with stratification\n",
    "for name in list(country_list):  \n",
    "    M_X_train[name], M_X_test[name], M_Y_train[name], M_Y_test[name] = train_test_split(CM_train[name], CM_Y_train[name], test_size=0.2, stratify=CM_Y_train[name], random_state=random_seed)\n",
    "    \n",
    "# split between train (80%) and test (20%) with stratification\n",
    "for name in list(country_list):  \n",
    "    F_X_train[name], F_X_test[name], F_Y_train[name], F_Y_test[name] = train_test_split(CF_train[name], CF_Y_train[name], test_size=0.2, stratify=CF_Y_train[name], random_state=random_seed)\n",
    "    \n",
    "# multiple imputations using chained equations\n",
    "n_imputations = 5\n",
    "M_X_train_comp = {}\n",
    "M_X_test_comp = {}\n",
    "CM_test_comp = {}\n",
    "M_X_train_imp = {}\n",
    "M_X_test_imp = {}\n",
    "CM_test_imp = {}\n",
    "\n",
    "\n",
    "n_imputations = 5\n",
    "F_X_train_comp = {}\n",
    "F_X_test_comp = {}\n",
    "CF_test_comp = {}\n",
    "F_X_train_imp = {}\n",
    "F_X_test_imp = {}\n",
    "CF_test_imp = {}\n",
    "\n",
    "for name in list(country_list):\n",
    "    M_X_train_comp[name] = []\n",
    "    M_X_test_comp[name] = []\n",
    "    CM_test_comp[name] = []\n",
    "    \n",
    "for name in list(country_list):\n",
    "    F_X_train_comp[name] = []\n",
    "    F_X_test_comp[name] = []\n",
    "    CF_test_comp[name] = []\n",
    "    \n",
    "    for i in range(n_imputations):\n",
    "        print(f'Current imputed country is {name}')\n",
    "        print(f'Current imputation round is {i+1}/{n_imputations}')\n",
    "        M_imputer = IterativeImputer(sample_posterior=True, random_state=i, verbose=1)\n",
    "        M_X_train_comp[name].append(M_imputer.fit_transform(M_X_train[name]))\n",
    "        M_X_test_comp[name].append(M_imputer.transform(M_X_test[name]))\n",
    "        CM_test_comp[name].append(M_imputer.transform(CM_test[name]))\n",
    "        \n",
    "    for i in range(n_imputations):\n",
    "        print(f'Current imputed country is {name}')\n",
    "        print(f'Current imputation round is {i+1}/{n_imputations}')\n",
    "        F_imputer = IterativeImputer(sample_posterior=True, random_state=i, verbose=1)\n",
    "        F_X_train_comp[name].append(F_imputer.fit_transform(F_X_train[name]))\n",
    "        F_X_test_comp[name].append(F_imputer.transform(F_X_test[name]))\n",
    "        CF_test_comp[name].append(F_imputer.transform(CF_test[name]))\n",
    "        \n",
    "    M_X_train_imp[name] = pd.DataFrame(np.mean(M_X_train_comp[name], axis=0), columns=M_C_D_col_names)\n",
    "    M_X_test_imp[name] = pd.DataFrame(np.mean(M_X_test_comp[name], axis=0), columns=M_C_D_col_names)\n",
    "    CM_test_imp[name] = pd.DataFrame(np.mean(CM_test_comp[name], axis=0), columns=M_C_D_col_names)\n",
    "    \n",
    "    \n",
    "    F_X_train_imp[name] = pd.DataFrame(np.mean(F_X_train_comp[name], axis=0), columns=F_C_D_col_names)\n",
    "    F_X_test_imp[name] = pd.DataFrame(np.mean(F_X_test_comp[name], axis=0), columns=F_C_D_col_names)\n",
    "    CF_test_imp[name] = pd.DataFrame(np.mean(CF_test_comp[name], axis=0), columns=F_C_D_col_names)\n",
    "    \n",
    "# imputation processing\n",
    "def min_max_int(df, column, nb_cat=float('inf')):\n",
    "    df[column] = round(df[column], 0)\n",
    "    df[column][df[column] < 0] = 0\n",
    "    df[column][df[column] > nb_cat - 1] = nb_cat - 1\n",
    "    return df\n",
    "\n",
    "def onehot(df, name):\n",
    "    onehot = pd.DataFrame()\n",
    "    for colonne in list(df.columns):\n",
    "        if re.match(name, colonne):\n",
    "            for indice in df[colonne][~df[colonne].isin([0, 1])].index:\n",
    "                onehot.loc[indice, colonne] = df.loc[indice, colonne]\n",
    "    i = 0\n",
    "    for indice in onehot.index:\n",
    "        onehot.loc[indice, list(onehot.idxmax(axis=1))[i]] = 1\n",
    "        i += 1\n",
    "    onehot[onehot!=1] = 0\n",
    "    df.update(onehot)\n",
    "    return df\n",
    "\n",
    "M_X_train_proc =  {}\n",
    "M_X_test_proc =  {}\n",
    "CM_test_proc =  {}\n",
    "\n",
    "F_X_train_proc =  {}\n",
    "F_X_test_proc =  {}\n",
    "CF_test_proc =  {}\n",
    "        \n",
    "        \n",
    "for name in list(country_list):\n",
    "    \n",
    "    def M_imp_process(df):\n",
    "    \n",
    "        min_max_int(df, 'Age')\n",
    "        onehot(df, 'Relationship with family head')\n",
    "        min_max_int(df, 'Respondent live in household', 2)\n",
    "        min_max_int(df, 'Known HIV status', 2)\n",
    "        min_max_int(df, 'Bought/sold sex in the past 12 months', 2)\n",
    "        min_max_int(df, 'Condom was used at last paid sex in past 12 months', 2)\n",
    "        min_max_int(df, 'LAg: recent/long term infection', 2)\n",
    "        min_max_int(df, 'CD4 category', 5)\n",
    "        min_max_int(df, 'on ART', 2)\n",
    "        min_max_int(df, 'ART initiated past 12 months those ever on ART', 2)\n",
    "        onehot(df, 'last sex partner relations past 12 months')\n",
    "        min_max_int(df, 'Sick to work last three months', 3)\n",
    "        min_max_int(df, 'Ever attended school',2)    \n",
    "        min_max_int(df, 'Ever enrolled in school', 2)\n",
    "        onehot(df, 'Highest level of education')    \n",
    "        min_max_int(df, 'Highest grade at that school level')\n",
    "        min_max_int(df, 'Work for payment in last 12 months',2)\n",
    "        min_max_int(df, 'Ever married/lived together',2)\n",
    "        min_max_int(df, 'Avoiding pregnancy',3)    \n",
    "        min_max_int(df, 'CFcumcision status',2)\n",
    "        min_max_int(df, 'Age at fFst sex')      \n",
    "        min_max_int(df, 'Ever sought TB treatment', 2)    \n",
    "        onehot(df, 'Alcohol drink frequency')    \n",
    "        min_max_int(df, 'Urban area indicator',2)      \n",
    "        onehot(df, 'Wealth quintile')    \n",
    "        min_max_int(df, 'Sexual intercourse in the past 12 months', 2)    \n",
    "        min_max_int(df, 'Ever had sexual intercourse', 2) \n",
    "        \n",
    "        return df\n",
    "    \n",
    "for name in list(country_list):\n",
    "    M_X_train_proc[name] = M_imp_process(M_X_train_imp[name])\n",
    "    M_X_test_proc[name] = M_imp_process(M_X_test_imp[name])\n",
    "    CM_test_proc[name] = M_imp_process(CM_test_imp[name])\n",
    "  \n",
    "                  \n",
    "def F_imp_process(df):\n",
    "    min_max_int(df, 'Age')\n",
    "    onehot(df, 'Current marital status')\n",
    "    min_max_int(df, 'Number of pregnancies')\n",
    "    min_max_int(df, 'Self-reported ARV status during pregnancy',2)\n",
    "    min_max_int(df, 'Bought/sold sex in the past 12 months',2)\n",
    "    min_max_int(df, 'Condom was used at last paid sex in past 12 months',2)\n",
    "    onehot(df, 'last sex partner relations past 12 months')\n",
    "    min_max_int(df, 'CD4 category',2)\n",
    "    min_max_int(df, 'On ART',2)\n",
    "    min_max_int(df, 'ART initiated past 12 months those ever on ART',2)\n",
    "    min_max_int(df, 'Whether ARVs detected',2)\n",
    "    min_max_int(df, 'LAg: recent/long term infection',2)\n",
    "    min_max_int(df, 'Breastfed last child',2)\n",
    "    min_max_int(df, 'Delivered 12 months preceeding survey',2)\n",
    "    min_max_int(df, 'Ever had a pregnancy that resulted in a live bFth',2)\n",
    "    min_max_int(df, 'No. of childen given bFth since 2012')\n",
    "    min_max_int(df, 'Pregnacy status now') \n",
    "    min_max_int(df, 'Known HIV status',2)\n",
    "    onehot(df, 'Relationship with family head')\n",
    "    min_max_int(df, 'Respondent live in household', 2)\n",
    "    min_max_int(df, 'Sick to work last three months', 3)\n",
    "    min_max_int(df, 'Ever attended school',2)    \n",
    "    min_max_int(df, 'Ever enrolled in school', 2)\n",
    "    onehot(df, 'Highest level of education')    \n",
    "    min_max_int(df, 'Highest grade at that school level')\n",
    "    min_max_int(df, 'Work for payment in last 12 months',2)\n",
    "    min_max_int(df, 'Ever married/lived together',2)\n",
    "    min_max_int(df, 'Avoiding pregnancy',3)    \n",
    "    min_max_int(df, 'Age at fFst sex')      \n",
    "    min_max_int(df, 'tested HIV at pregnancy',2)\n",
    "    min_max_int(df, 'Ever sought TB treatment', 2)    \n",
    "    onehot(df, 'Alcohol drink frequency')    \n",
    "    min_max_int(df, 'Urban area indicator',2)      \n",
    "    onehot(df, 'Wealth quintile')    \n",
    "    min_max_int(df, 'Sexual intercourse past 12 months', 2)    \n",
    "    min_max_int(df, 'Ever had sexual intercourse', 2)    \n",
    "     \n",
    "    return df\n",
    "\n",
    "for name in list(country_list):\n",
    "    F_X_train_proc[name] = F_imp_process(F_X_train_imp[name])\n",
    "    F_X_test_proc[name] = F_imp_process(F_X_test_imp[name])\n",
    "    CF_test_proc[name] = F_imp_process(CF_test_imp[name])\n",
    "\n",
    "    \n",
    "M_X_train_ready = {}\n",
    "M_X_test_ready = {}\n",
    "CM_test_ready = {}\n",
    "\n",
    "F_X_train_ready = {}\n",
    "F_X_test_ready = {}\n",
    "CF_test_ready = {}\n",
    "\n",
    "\n",
    "# standardization of the data\n",
    "for name in list(country_list):\n",
    "    M_scaler = StandardScaler(with_mean=False)\n",
    "    M_X_train_ready[name] = round(pd.DataFrame(M_scaler.fit_transform(M_X_train_proc[name]), columns=M_C_D_col_names), 2)\n",
    "    M_X_test_ready[name] = round(pd.DataFrame(M_scaler.transform(M_X_test_proc[name]), columns=M_C_D_col_names), 2)\n",
    "    CM_test_ready[name] = round(pd.DataFrame(M_scaler.transform(CM_test_proc[name]), columns=M_C_D_col_names), 2)\n",
    "    M_var = M_scaler.var_\n",
    "   \n",
    "# standardization of the data\n",
    "for name in list(country_list):\n",
    "    F_scaler = StandardScaler(with_mean=False)\n",
    "    F_X_train_ready[name] = round(pd.DataFrame(F_scaler.fit_transform(F_X_train_proc[name]), columns=F_C_D_col_names), 2)\n",
    "    F_X_test_ready[name] = round(pd.DataFrame(F_scaler.transform(F_X_test_proc[name]), columns=F_C_D_col_names), 2)\n",
    "    CF_test_ready[name] = round(pd.DataFrame(F_scaler.transform(CF_test_proc[name]), columns=F_C_D_col_names), 2)\n",
    "    F_var = F_scaler.var_  \n",
    "    \n",
    "# pickling data\n",
    "f = open(\"Imputation_data\\M_X_train_imp.pkl\", 'wb')\n",
    "pickle.dump(M_X_train_imp, f)\n",
    "\n",
    "# pickling data\n",
    "f = open(\"Imputation_data\\F_X_train_imp.pkl\", 'wb')\n",
    "pickle.dump(F_X_train_imp, f)\n",
    "f = open(\"Imputation_data\\M_X_test_imp.pkl\", 'wb')\n",
    "pickle.dump(M_X_test_imp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_X_test_imp.pkl\", 'wb')\n",
    "pickle.dump(F_X_test_imp, f)\n",
    "f = open(\"Imputation_data\\CM_test_imp.pkl\", 'wb')\n",
    "pickle.dump(CM_test_imp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\CF_test_imp.pkl\", 'wb')\n",
    "pickle.dump(CF_test_imp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\M_X_train_comp.pkl\", 'wb')\n",
    "pickle.dump(M_X_train_comp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_X_train_comp.pkl\", 'wb')\n",
    "pickle.dump(F_X_train_comp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\M_X_test_comp.pkl\", 'wb')\n",
    "pickle.dump(M_X_test_comp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_X_test_comp.pkl\", 'wb')\n",
    "pickle.dump(F_X_test_comp, f)\n",
    "f = open(\"Imputation_data\\CM_test_comp.pkl\", 'wb')\n",
    "pickle.dump(CM_test_comp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\CF_test_comp.pkl\", 'wb')\n",
    "pickle.dump(CF_test_comp, f)\n",
    "\n",
    "f = open(\"Imputation_data\\M_X_train_proc.pkl\", 'wb')\n",
    "pickle.dump(M_X_train_proc, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_X_train_proc.pkl\", 'wb')\n",
    "pickle.dump(F_X_train_proc, f)\n",
    "\n",
    "f = open(\"Imputation_data\\M_X_test_proc.pkl\", 'wb')\n",
    "pickle.dump(M_X_test_proc, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_X_test_proc.pkl\", 'wb')\n",
    "pickle.dump(F_X_test_proc, f)\n",
    "\n",
    "f = open(\"Imputation_data\\CM_test_proc.pkl\", 'wb')\n",
    "pickle.dump(CM_test_proc, f)\n",
    "\n",
    "\n",
    "f = open(\"Imputation_data\\CF_test_proc.pkl\", 'wb')\n",
    "pickle.dump(CF_test_proc, f)\n",
    "\n",
    "f = open(\"Train_samples\\M_X_train_ready.pkl\", 'wb')\n",
    "pickle.dump(M_X_train_ready, f)\n",
    "\n",
    "f = open(\"Train_samples\\F_X_train_ready.pkl\", 'wb')\n",
    "pickle.dump(F_X_train_ready, f)\n",
    "\n",
    "f = open(\"Test_samples\\M_X_test_ready.pkl\", 'wb')\n",
    "pickle.dump(M_X_test_ready, f)\n",
    "\n",
    "f = open(\"Test_samples\\F_X_test_ready.pkl\", 'wb')\n",
    "pickle.dump(F_X_test_ready, f)\n",
    "\n",
    "\n",
    "f = open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'wb')\n",
    "pickle.dump(CM_test_ready, f)\n",
    "\n",
    "f = open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'wb')\n",
    "pickle.dump(CF_test_ready, f)\n",
    "\n",
    "f = open(\"Train_samples\\M_Y_train.pkl\", 'wb')\n",
    "pickle.dump(M_Y_train, f)\n",
    "\n",
    "f = open(\"Train_samples\\F_Y_train.pkl\", 'wb')\n",
    "pickle.dump(F_Y_train, f)\n",
    "\n",
    "\n",
    "f = open(\"Test_samples\\M_Y_test.pkl\", 'wb')\n",
    "pickle.dump(M_Y_test, f)\n",
    "\n",
    "f = open(\"Test_samples\\F_Y_test.pkl\", 'wb')\n",
    "pickle.dump(F_Y_test, f)\n",
    "\n",
    "\n",
    "f = open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'wb')\n",
    "pickle.dump(CM_Y_test, f)\\\n",
    "\n",
    "\n",
    "f = open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'wb')\n",
    "pickle.dump(CF_Y_test, f)\n",
    "\n",
    "f = open(\"Imputation_data\\M_var.pkl\", 'wb')\n",
    "pickle.dump(M_var, f)\n",
    "\n",
    "f = open(\"Imputation_data\\F_var.pkl\", 'wb')\n",
    "pickle.dump(F_var, f)\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
