{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve\n",
    "random_seed = 10\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test = pd.concat(CM_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test = pd.concat(CF_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "    \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "# parameters space, models definition and random grid search\n",
    "#================================================================================================================================\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "scoring = ['f1', 'recall', 'precision']\n",
    "\n",
    "# XGBoost space\n",
    "params_xgb = {'learning_rate': np.linspace(0, 1, 11),\n",
    "              'min_split_loss': np.linspace(0, 1, 6),\n",
    "              'max_depth': np.linspace(2, 10, 5, dtype=int),\n",
    "              'min_child_weight': np.linspace(1, 20, 20, dtype=int),\n",
    "              'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "              'reg_alpha': np.linspace(0, 1, 11),\n",
    "              'scale_pos_weight': np.linspace(4, 50, 24, dtype=int),\n",
    "              'n_estimators': np.linspace(10, 450, 12, dtype=int),\n",
    "              'reg_lambda': np.linspace(0, 10, 11),\n",
    "             }\n",
    "\n",
    "M_xgb_sample = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=50,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "F_xgb_sample = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=50,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "M_xgb_sample.fit(M_X_train_ready_selected, M_Y_train_ready)\n",
    "dump(M_xgb_sample, \"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "F_xgb_sample.fit(F_X_train_ready_selected, F_Y_train_ready)\n",
    "dump(F_xgb_sample, \"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test_ready = pd.concat(CM_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test_ready = pd.concat(CF_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "    \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "CM_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "CF_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_ready_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_ready_selected)\n",
    "\n",
    "print('Confusion matrix on the  M train dataset:', confusion_matrix(M_Y_train_ready, M_Y_train_selected_pred))\n",
    "print('Average F1 score on the  M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_f1'][M_best_index]))\n",
    "print('CI F1 score on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_f1'][M_best_index]))\n",
    "print('Average Sensitivity on the M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_recall'][M_best_index]))\n",
    "print('CI Sensitivity on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_recall'][M_best_index]))\n",
    "print('Average Positive Predictive Value on the M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_precision'][M_best_index]))\n",
    "print('CI Positive Predictive Value on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_precision'][M_best_index]))\n",
    "print('Parameters', M_xgb_selected.best_estimator_)\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_ready, F_Y_train_selected_pred))\n",
    "print('Average F1 score on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_f1'][F_best_index]))\n",
    "print('CI F1 score on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_f1'][F_best_index]))\n",
    "print('Average Sensitivity on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_recall'][F_best_index]))\n",
    "print('CI Sensitivity on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_recall'][F_best_index]))\n",
    "print('Average Positive Predictive Value on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_precision'][F_best_index]))\n",
    "print('CI Positive Predictive Value on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_precision'][F_best_index]))\n",
    "print('Parameters', F_xgb_selected.best_estimator_)\n",
    "\n",
    "from matplotlib import pyplot   \n",
    "M_Y_test_selected_pred = M_xgb_selected.predict(M_X_test_ready_selected)\n",
    "F_Y_test_selected_pred = F_xgb_selected.predict(F_X_test_ready_selected)\n",
    "CM_Y_test_selected_pred = M_xgb_selected.predict(CM_test_ready_selected)\n",
    "CF_Y_test_selected_pred = F_xgb_selected.predict(CF_test_ready_selected)\n",
    "\n",
    "\n",
    "\n",
    "print('Confusion matrix on the M test dataset:', confusion_matrix(M_Y_test_ready, M_Y_test_selected_pred))\n",
    "print('F1 score on the M test dataset:', \"{:.1%}\".format(f1_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "\n",
    "print('Sensitivity on the M test dataset:', \"{:.1%}\".format(recall_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the M test dataset:', \"{:.1%}\".format(precision_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F test dataset:', confusion_matrix(F_Y_test_ready, F_Y_test_selected_pred))\n",
    "print('F1 score on the F test dataset:', \"{:.1%}\".format(f1_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Sensitivity on the F test dataset:', \"{:.1%}\".format(recall_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the F test dataset:', \"{:.1%}\".format(precision_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the CF  test dataset:', confusion_matrix(CF_Y_test_ready, CF_Y_test_selected_pred))\n",
    "print('F1 score on the CF test dataset:', \"{:.1%}\".format(f1_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "print('Sensitivity on the CF test dataset:', \"{:.1%}\".format(recall_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the CF test dataset:', \"{:.1%}\".format(precision_score(CF_Y_test_ready, CF_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the CM test dataset:', confusion_matrix(CM_Y_test_ready, CM_Y_test_selected_pred))\n",
    "print('F1 score on the CM test dataset:', \"{:.1%}\".format(f1_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "print('Sensitivity on the CM test dataset:', \"{:.1%}\".format(recall_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the CM test dataset:', \"{:.1%}\".format(precision_score(CM_Y_test_ready, CM_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "         dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "         dy_test_predict = model.predict(dx_test)\n",
    "         ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "         F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "         print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "         prevalence = np.sum(dy_test)/len(dy_test)\n",
    "         pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "         pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "         pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "         pyplot.xlabel('Sensitivity')\n",
    "         pyplot.ylabel('Positive Predicted Value')\n",
    "         pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "         pyplot.title('Precisio Recall Curve-Males')   \n",
    "         pyplot.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "pr_f1_curve(M_xgb_selected, M_X_test_ready_selected, M_Y_test_ready)\n",
    "# pr_f1_curve(F_xgb_selected, F_X_test_ready_selected, F_Y_test_ready)\n",
    "# pr_f1_curve(CF_xgb_selected, CF_test_ready_selected, CF_Y_test_ready)\n",
    "# pr_f1_curve(CM_xgb_selected, CM_test_ready_selected, CM_Y_test_ready)\n",
    "\n",
    "\n",
    "# Explain model predictions using shapley value\n",
    "# M_explainer = shap.TreeExplainer(M_xgb_selected.best_estimator_)\n",
    "# M_shap_values = M_explainer.shap_values(M_X_train_ready_selected)\n",
    "# F_explainer = shap.TreeExplainer(F_xgb_selected.best_estimator_)\n",
    "# F_shap_values = F_explainer.shap_values(F_X_train_ready_selected)\n",
    "\n",
    "# CF_explainer = shap.TreeExplainer(CF_xgb_selected.best_estimator_)\n",
    "# CF_shap_values = CF_explainer.shap_values(CF_test_ready_selected)\n",
    "# \n",
    "# CM_explainer = shap.TreeExplainer(CM_xgb_selected.best_estimator_)\n",
    "# CM_shap_values = CM_explainer.shap_values(CM_test_ready_selected)\n",
    "\n",
    "# Plot summary_plot\n",
    "# shap.summary_plot(M_shap_values, M_X_train_ready_selected, max_display=24)\n",
    "# shap.summary_plot(F_shap_values, F_X_train_ready_selected, max_display=29)\n",
    "\n",
    "# shap.summary_plot(CM_shap_values, CM_test_ready_selected, max_display=24)\n",
    "# shap.summary_plot(CF_shap_values, CF_test_ready_selected, max_display=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test_ready = pd.concat(CM_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test_ready = pd.concat(CF_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "    \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "CM_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "CF_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_ready_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_ready_selected)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot   \n",
    "M_Y_test_selected_pred = M_xgb_selected.predict(M_X_test_ready_selected)\n",
    "F_Y_test_selected_pred = F_xgb_selected.predict(F_X_test_ready_selected)\n",
    "CM_Y_test_selected_pred = M_xgb_selected.predict(CM_test_ready_selected)\n",
    "CF_Y_test_selected_pred = F_xgb_selected.predict(CF_test_ready_selected)\n",
    "\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "         dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "         dy_test_predict = model.predict(dx_test)\n",
    "         ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "         F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "         print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "         prevalence = np.sum(dy_test)/len(dy_test)\n",
    "         pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "         pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "         pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "         pyplot.xlabel('Sensitivity')\n",
    "         pyplot.ylabel('Positive Predicted Value')\n",
    "         pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "         pyplot.title('Precision-Recall Curve-Females')   \n",
    "         pyplot.show()\n",
    "            \n",
    "       \n",
    "        \n",
    "    \n",
    "        \n",
    "# pr_f1_curve(M_xgb_selected, M_X_test_ready_selected, M_Y_test_ready)\n",
    "pr_f1_curve(F_xgb_selected, F_X_test_ready_selected, F_Y_test_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test_ready = pd.concat(CM_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test_ready = pd.concat(CF_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "    \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "CM_xgb_selected = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "CF_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "M_model = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_model = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test = pd.concat(CM_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test = pd.concat(CF_Y_test.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "    \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "\n",
    "# precision-recall curve and f1\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(M_X_train_ready_selected, M_Y_train_ready)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(M_X_test_ready_selected)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = model.predict(M_X_test_ready_selected)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(M_Y_test_ready, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(M_Y_test_ready, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(M_Y_test_ready[M_Y_test_ready==1]) / len(M_Y_test_ready)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sk_metrics\n",
    "    \n",
    "def f_beta_by_threshold(y_true, y_pred_pos, beta, thres_nr=100):\n",
    "    thresholds = [i / thres_nr for i in range(1, thres_nr, 1)]\n",
    "\n",
    "    f_scores = []\n",
    "    for thres in thresholds:\n",
    "        y_pred_class = y_pred_pos > thres\n",
    "        score = sk_metrics.fbeta_score(y_true, y_pred_class, beta=beta)\n",
    "        f_scores.append(score)\n",
    "\n",
    "    return thresholds, f_scores\n",
    "\n",
    "betas = [0.1, 0.25, 0.5, 1.0, 1.25, 1.5, 2, 5, 10]\n",
    "\n",
    "fig, ax = pyplot.subplots()\n",
    "for beta in betas:\n",
    "    thresholds, scores = f_beta_by_threshold(M_Y_test_ready, M_Y_test_ready_pred[:, 1], beta)\n",
    "    ax.plot(thresholds, scores, label='beta={}'.format(beta))\n",
    "    ax.set_title('F beta(threshold) by beta')\n",
    "    ax.set_xlabel('threshold')\n",
    "    ax.set_ylabel('F beta')\n",
    "    ax.legend(loc='right', bbox_to_anchor=(1.3,0.7))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "M_model = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_model = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "M_precision, M_recall, M_thresholds = precision_recall_curve(M_Y_test_ready, M_model.predict_proba(M_X_test_ready_selected)[:,1])\n",
    "\n",
    "M_f1 = 2*M_recall*M_precision/(M_recall+M_precision)\n",
    "\n",
    "F_precision, F_recall, F_thresholds = precision_recall_curve(F_Y_test_ready, F_model.predict_proba(F_X_test_ready_selected)[:,1])\n",
    "\n",
    "F_f1 = 2*F_recall*F_precision/(F_recall+F_precision)\n",
    "\n",
    "\n",
    "M_index = np.argmax(M_precision[(M_recall>=0.949999999) & (M_recall >= 0.9500000001)])\n",
    "\n",
    "print('Males')\n",
    "print('Best f1: ', M_f1[M_index])\n",
    "print('Best precision: ', M_precision[M_index])\n",
    "print('Best threshold: ', M_thresholds[M_index])\n",
    "\n",
    "F_index = np.argmax(F_precision[(F_recall>=0.949999999) & (F_recall >= 0.9500000001)])\n",
    "\n",
    "print('Females')\n",
    "print('Best f1: ', F_f1[F_index])\n",
    "print('Best precision: ', F_precision[F_index])\n",
    "print('Best threshold: ', F_thresholds[F_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M_Y_test_pred_thresh = (M_model.predict_proba(M_X_test_ready_selected)[:,1] >= 0.00661738).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_pred_thresh)\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model.predict_proba(F_X_test_ready_selected)[:,1] >= 0.05414463).astype(bool)\n",
    "\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_ready, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Y_test_pred_thresh = (M_model.predict_proba(M_X_test_ready_selected)[:,1] >= 0.95).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_pred_thresh)\n",
    "\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model.predict_proba(F_X_test_ready_selected)[:,1] >= 0.95).astype(bool)\n",
    "\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_ready, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1-Score: ', np.max(M_f1))\n",
    "print('Best precision: ', M_precision[np.argmax(M_f1)])\n",
    "print('Best recall: ', M_recall[np.argmax(M_f1)])\n",
    "print('Best threshold: ', M_thresholds[np.argmax(M_f1)])\n",
    "\n",
    "print('Best F1-Score: ', np.max(F_f1))\n",
    "print('Best precision: ', F_precision[np.argmax(F_f1)])\n",
    "print('Best recall: ', F_recall[np.argmax(F_f1)])\n",
    "print('Best threshold: ', F_thresholds[np.argmax(F_f1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "# code for uploading pickled data\n",
    "\n",
    "# code for uploading pickled data\n",
    "# M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "# M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "# F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "# F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "# F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "# F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "M_model = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "# F_model = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "M_sfs_samples = SFS(M_model.best_estimator_, k_features=27, forward=True, floating=False, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "# F_sfs = SFS(F_model.best_estimator_, k_features=35, forward=True, floating=True, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "\n",
    "M_sfs_samples.fit(M_X_train_ready, M_Y_train_ready)\n",
    "# F_sfs.fit(F_X_train_ready, F_Y_train_ready)\n",
    "\n",
    "dump(M_sfs_samples, 'M_sfs_samples.joblib')\n",
    "# dump(F_sfs_samples, 'F_sfs_samples.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "# code for uploading pickled data\n",
    "\n",
    "# code for uploading pickled data\n",
    "# M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "# M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "# M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "# M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "# M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "# M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# M_model = load(\"xgb_sample\\M_xgb_sample_sample_data.joblib\")\n",
    "F_model = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "# M_sfs = SFS(M_model.best_estimator_, k_features=27, forward=True, floating=False, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "F_sfs_samples = SFS(F_model.best_estimator_, k_features=35, forward=True, floating=True, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "\n",
    "# M_sfs.fit(M_X_train_ready, M_Y_train_ready)\n",
    "F_sfs_samples.fit(F_X_train_ready, F_Y_train_ready)\n",
    "\n",
    "# dump(M_sfs_samples, 'M_sfs_samples.joblib')\n",
    "dump(F_sfs_samples, 'F_sfs_samples.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "M_sfs_samples.subsets_\n",
    "# F_sfs_samples.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sfs_samples = load(\"M_sfs_samples.joblib\")\n",
    "M_sfs_samples.subsets_\n",
    "# F_sfs_samples = load(\"F_sfs_samples.joblib\")\n",
    "# F_sfs_samples.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(M_sfs_samples.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0.3, 1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(F_sfs_samples.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0.85, 1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "plot_sfs(M_sfs_samples.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(10, 6))\n",
    "\n",
    "plt.ylim([0.3, 1])\n",
    "plt.xlabel('Number of variables', fontsize=20)\n",
    "plt.ylabel('f1 score', fontsize=20)\n",
    "plt.title('SFFS - males', fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig('M_sfs_samples.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Respondent live in household',\n",
    "   'Sick to work last three months',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile',\n",
    "   'Sexual intercourse in the past 12 months',\n",
    "   'Bought/sold sex in the past 12 months',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'last sex partner relations past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'CD4 category',\n",
    "   'ART initiated past 12 months those ever on ART']  \n",
    "M_X_train_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Delivered 12 months preceeding survey',\n",
    "   'Self-reported ARV status during pregnancy',\n",
    "   'Sexual intercourse past 12 months',\n",
    "   'Ever had sexual intercourse',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'On ART',\n",
    "   'ART initiated past 12 months those ever on ART',\n",
    "   'Whether ARVs detected']    \n",
    "     \n",
    "F_X_train_selected = F_X_train_ready[F_selected_features]\n",
    "\n",
    "#================================================================================================================================\n",
    "# parameters space, models definition and random grid search\n",
    "#================================================================================================================================\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "scoring = ['f1', 'recall', 'precision']\n",
    "\n",
    "# XGBoost space\n",
    "params_xgb = {'learning_rate': np.linspace(0, 1, 11),\n",
    "              'min_split_loss': np.linspace(0, 1, 6),\n",
    "              'max_depth': np.linspace(2, 10, 5, dtype=int),\n",
    "              'min_child_weight': np.linspace(1, 20, 20, dtype=int),\n",
    "              'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "              'reg_alpha': np.linspace(0, 1, 11),\n",
    "              'scale_pos_weight': np.linspace(4, 50, 24, dtype=int),\n",
    "              'n_estimators': np.linspace(10, 450, 12, dtype=int),\n",
    "              'reg_lambda': np.linspace(0, 10, 11),\n",
    "             }\n",
    "\n",
    "M_xgb_selected_21_samples = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "F_xgb_selected_20 = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "M_xgb_selected_21_samples.fit(M_X_train_selected, M_Y_train_ready)\n",
    "dump(M_xgb_selected_21_samples, \"xgb_selected\\M_xgb_selected_21_sample_data.joblib\")\n",
    "\n",
    "F_xgb_selected_20.fit(F_X_train_selected, F_Y_train_ready)\n",
    "dump(F_xgb_selected_20, \"xgb_selected\\F_xgb_selected_20_sample_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import bisect \n",
    "from scipy.stats import mstats\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "# select features\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Respondent live in household',\n",
    "   'Sick to work last three months',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile',\n",
    "   'Sexual intercourse in the past 12 months',\n",
    "   'Bought/sold sex in the past 12 months',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'last sex partner relations past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'CD4 category',\n",
    "   'ART initiated past 12 months those ever on ART']  \n",
    "M_X_train_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Delivered 12 months preceeding survey',\n",
    "   'Self-reported ARV status during pregnancy',\n",
    "   'Sexual intercourse past 12 months',\n",
    "   'Ever had sexual intercourse',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'On ART',\n",
    "   'ART initiated past 12 months those ever on ART',\n",
    "   'Whether ARVs detected']    \n",
    "     \n",
    "F_X_train_selected = F_X_train_ready[F_selected_features]\n",
    "\n",
    "M_model_21 = load(\"xgb_selected\\M_xgb_selected_21_sample_data.joblib\")\n",
    "F_model_20 = load(\"xgb_selected\\F_xgb_selected_20_sample_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Respondent live in household',\n",
    "   'Sick to work last three months',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile',\n",
    "   'Sexual intercourse in the past 12 months',\n",
    "   'Bought/sold sex in the past 12 months',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'last sex partner relations past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'CD4 category',\n",
    "   'ART initiated past 12 months those ever on ART']  \n",
    "M_X_train_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Delivered 12 months preceeding survey',\n",
    "   'Self-reported ARV status during pregnancy',\n",
    "   'Sexual intercourse past 12 months',\n",
    "   'Ever had sexual intercourse',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'On ART',\n",
    "   'ART initiated past 12 months those ever on ART',\n",
    "   'Whether ARVs detected']    \n",
    "     \n",
    "F_X_train_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_selected = F_X_test_ready[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_selected\\M_xgb_selected_21_sample_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_selected\\F_xgb_selected_20_sample_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_selected)\n",
    "\n",
    "print('Confusion matrix on the train dataset:', confusion_matrix(M_Y_train_ready, M_Y_train_selected_pred))\n",
    "print('Average F1 score on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_f1'][M_best_index]))\n",
    "print('CI F1 score on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_f1'][M_best_index]))\n",
    "print('Average Sensitivity on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_recall'][M_best_index]))\n",
    "print('CI Sensitivity on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_recall'][M_best_index]))\n",
    "print('Average Positive Predictive Value on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_precision'][M_best_index]))\n",
    "print('CI Positive Predictive Value on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_precision'][M_best_index]))\n",
    "print('Parameters', M_xgb_selected.best_estimator_)\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_ready, F_Y_train_selected_pred))\n",
    "print('Average F1 score on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_f1'][F_best_index]))\n",
    "print('CI F1 score on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_f1'][F_best_index]))\n",
    "print('Average Sensitivity on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_recall'][F_best_index]))\n",
    "print('CI Sensitivity on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_recall'][F_best_index]))\n",
    "print('Average Positive Predictive Value on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_precision'][F_best_index]))\n",
    "print('CI Positive Predictive Value on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_precision'][F_best_index]))\n",
    "print('Parameters', F_xgb_selected.best_estimator_)\n",
    "     \n",
    "M_Y_test_selected_pred = M_xgb_selected.predict(M_X_test_selected)\n",
    "F_Y_test_selected_pred = F_xgb_selected.predict(F_X_test_selected)\n",
    "\n",
    "print('Confusion matrix on the test dataset:', confusion_matrix(M_Y_test_ready, M_Y_test_selected_pred))\n",
    "print('F1 score on the test dataset:', \"{:.1%}\".format(f1_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "print('Sensitivity on the test dataset:', \"{:.1%}\".format(recall_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the test dataset:', \"{:.1%}\".format(precision_score(M_Y_test_ready, M_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the F test dataset:', confusion_matrix(F_Y_test_ready, F_Y_test_selected_pred))\n",
    "print('F1 score on the F test dataset:', \"{:.1%}\".format(f1_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Sensitivity on the F test dataset:', \"{:.1%}\".format(recall_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the F test dataset:', \"{:.1%}\".format(precision_score(F_Y_test_ready, F_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "     dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "     dy_test_predict = model.predict(dx_test)\n",
    "     ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "     F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "     print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "     prevalence = np.sum(dy_test)/len(dy_test)\n",
    "     pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "     pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "     pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "     pyplot.xlabel('Sensitivity')\n",
    "     pyplot.ylabel('Positive Predicted Value')\n",
    "     pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "     pyplot.show()\n",
    "\n",
    "pr_f1_curve(M_xgb_selected, M_X_test_selected, M_Y_test_ready)\n",
    "pr_f1_curve(F_xgb_selected, F_X_test_selected, F_Y_test_ready)\n",
    "\n",
    "# Explain model predictions using shapley value\n",
    "M_explainer = shap.TreeExplainer(M_xgb_selected.best_estimator_)\n",
    "M_shap_values = M_explainer.shap_values(M_X_train_selected)\n",
    "F_explainer = shap.TreeExplainer(F_xgb_selected.best_estimator_)\n",
    "F_shap_values = F_explainer.shap_values(F_X_train_selected)\n",
    "\n",
    "# Plot summary_plot\n",
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=21)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=20)\n",
    "plt.savefig('M_shapsample.jpg')\n",
    "plt.savefig('F_shapsample.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=21)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=20)\n",
    "plt.savefig('M_shapsample.jpg')\n",
    "plt.savefig('F_shapsample.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Respondent live in household',\n",
    "   'Sick to work last three months',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile',\n",
    "   'Sexual intercourse in the past 12 months',\n",
    "   'Bought/sold sex in the past 12 months',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'last sex partner relations past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'CD4 category',\n",
    "   'ART initiated past 12 months those ever on ART']  \n",
    "M_X_train_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Urban area indicator',\n",
    "   'Known HIV status',\n",
    "   'Delivered 12 months preceeding survey',\n",
    "   'Self-reported ARV status during pregnancy',\n",
    "   'Sexual intercourse past 12 months',\n",
    "   'Ever had sexual intercourse',\n",
    "   'Condom was used at last paid sex in past 12 months',\n",
    "   'LAg: recent/long term infection',\n",
    "   'On ART',\n",
    "   'ART initiated past 12 months those ever on ART',\n",
    "   'Whether ARVs detected']    \n",
    "     \n",
    "F_X_train_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_selected = F_X_test_ready[F_selected_features]\n",
    "\n",
    "M_model_21 = load(\"xgb_selected\\M_xgb_selected_21_sample_data.joblib\")\n",
    "F_model_20 = load(\"xgb_selected\\F_xgb_selected_20_sample_data.joblib\")\n",
    "M_precision, M_recall, M_thresholds = precision_recall_curve(M_Y_test_ready, M_model_21.predict_proba(M_X_test_selected)[:,1])\n",
    "\n",
    "M_f1 = 2*M_recall*M_precision/(M_recall+M_precision)\n",
    "\n",
    "F_precision, F_recall, F_thresholds = precision_recall_curve(F_Y_test_ready, F_model_20.predict_proba(F_X_test_selected)[:,1])\n",
    "\n",
    "F_f1 = 2*F_recall*F_precision/(F_recall+F_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_index = np.argmax(M_precision[(M_recall>=0.949999999) & (M_recall >= 0.9500000001)])\n",
    "\n",
    "print('Males')\n",
    "print('Best f1: ', M_f1[M_index])\n",
    "print('Best precision: ', M_precision[M_index])\n",
    "print('Best threshold: ', M_thresholds[M_index])\n",
    "\n",
    "F_index = np.argmax(F_precision[(F_recall>=0.899999999) & (F_recall >= 0.9000000001)])\n",
    "\n",
    "print('Females')\n",
    "print('Best f1: ', F_f1[F_index])\n",
    "print('Best precision: ', F_precision[F_index])\n",
    "print('Best threshold: ', F_thresholds[F_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M_Y_test_pred_thresh = (M_model_21.predict_proba(M_X_test_selected)[:,1] >= 0.014001296).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_pred_thresh)\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model_20.predict_proba(F_X_test_selected)[:,1] >= 0.4615294).astype(bool)\n",
    "\n",
    "# print('Females')\n",
    "# confusion_matrix(F_Y_test_ready, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Y_test_pred_thresh = (M_model_21.predict_proba(M_X_test_selected)[:,1] >= 0.90).astype(bool)\n",
    "F_Y_test_pred_thresh = (F_model_20.predict_proba(F_X_test_selected)[:,1] >= 0.90).astype(bool)\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_pred_thresh)\n",
    "# print('Females')\n",
    "# confusion_matrix(F_Y_test_ready, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1-Score: ', np.max(M_f1))\n",
    "print('Best precision: ', M_precision[np.argmax(M_f1)])\n",
    "print('Best recall: ', M_recall[np.argmax(M_f1)])\n",
    "print('Best threshold: ', M_thresholds[np.argmax(M_f1)])\n",
    "\n",
    "print('Best F1-Score: ', np.max(F_f1))\n",
    "print('Best precision: ', F_precision[np.argmax(F_f1)])\n",
    "print('Best recall: ', F_recall[np.argmax(F_f1)])\n",
    "print('Best threshold: ', F_thresholds[np.argmax(F_f1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_train_ready = pickle.load(open(\"Train_samples\\F_X_train_ready.pkl\", 'rb'))\n",
    "F_Y_train_ready = pickle.load(open(\"Train_samples\\F_Y_train.pkl\", 'rb'))\n",
    "F_X_train_ready = pd.concat(F_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_train_ready = pd.concat(F_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_test_ready = pickle.load(open(\"Test_samples\\M_X_test_ready.pkl\", 'rb'))\n",
    "M_Y_test_ready = pickle.load(open(\"Test_samples\\M_Y_test.pkl\", 'rb'))\n",
    "M_X_test_ready = pd.concat(M_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_test_ready = pd.concat(M_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_ready = pickle.load(open(\"Test_samples\\F_X_test_ready.pkl\", 'rb'))\n",
    "F_Y_test_ready = pickle.load(open(\"Test_samples\\F_Y_test.pkl\", 'rb'))\n",
    "F_X_test_ready = pd.concat(F_X_test_ready.values(), join='inner', ignore_index=True)\n",
    "F_Y_test_ready = pd.concat(F_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "CM_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_test_ready.pkl\", 'rb'))\n",
    "CM_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CM_Y_test.pkl\", 'rb'))\n",
    "CM_test_ready = pd.concat(CM_test_ready.values(), join='inner', ignore_index=True)\n",
    "CM_Y_test_ready = pd.concat(CM_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "\n",
    "CF_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_test_ready.pkl\", 'rb'))\n",
    "CF_Y_test_ready = pickle.load(open(\"Left_one_out_samples\\CF_Y_test.pkl\", 'rb'))\n",
    "CF_test_ready = pd.concat(CF_test_ready.values(), join='inner', ignore_index=True)\n",
    "CF_Y_test_ready = pd.concat(CF_Y_test_ready.values(), join='inner', ignore_index=True)\n",
    "M_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household','Sick to work last three months','Ever attended school','Ever enrolled in school'\n",
    "                        ,'Highest level of education', 'Highest grade at that school level','Work for payment in last 12 months',\n",
    "     'Ever married/lived together', 'Avoiding pregnancy','CFcumcision status','Age at fFst sex','Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'urban area indicator','Wealth quintile','Sexual intercourse in the past 12 months','Ever had sexual intercourse'] \n",
    " \n",
    "M_X_train_ready_selected = M_X_train_ready[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Current marital status', 'Number of pregnancies', 'Ever had a pregnancy that resulted in a live bFth',2)\n",
    "    , 'No. of childen given bFth since 2012', 'Pregnacy status now', 'Known HIV status', 'Relationship with family head','Respondent live in household',\n",
    "                        'Sick to work last three months','Ever attended school','Ever enrolled in school','Highest level of education', 'Highest grade at that school level',\n",
    "                        'Work for payment in last 12 months','Ever married/lived together','Avoiding pregnancy',\n",
    "                        'Age at fFst sex', 'Ever tested HIV','Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile','Sexual intercourse past 12 months','Ever had sexual intercourse']\n",
    "   \n",
    "     \n",
    "F_X_train_ready_selected = F_X_train_ready[F_selected_features]\n",
    "M_X_test_ready_selected = M_X_test_ready[M_selected_features]\n",
    "F_X_test_ready_selected = F_X_test_ready[F_selected_features]\n",
    "CM_test_ready_selected = CM_test_ready[M_selected_features]\n",
    "CF_test_ready_selected = CF_test_ready[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_selected\\M_xgb_selected_sample_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "CM_xgb_selected = load(\"xgb_selected\\M_xgb_selected_sample_data.joblib\")\n",
    "CF_xgb_selected = load(\"xgb_sample\\F_xgb_sample_sample_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_ready_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_ready_selected)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Confusion matrix on the M train dataset:', confusion_matrix(M_Y_train_ready, M_Y_train_selected_pred))\n",
    "print('F1 score on the M train dataset:', \"{:.1%}\".format(f1_score(M_Y_train_ready, M_Y_train_selected_pred)))\n",
    "print('Sensitivity on the M train dataset:', \"{:.1%}\".format(recall_score(M_Y_train_ready, M_Y_train_selected_pred)))\n",
    "print('Positive Predictive Value on the M train dataset:', \"{:.1%}\".format(precision_score(M_Y_train_ready, M_Y_train_selected_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_precision, M_recall, M_thresholds = precision_recall_curve(M_Y_test_ready, M_model.predict_proba(M_X_test_selected)[:,1])\n",
    "\n",
    "M_f1 = 2*M_recall*M_precision/(M_recall+M_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_index = np.argmax(M_precision[(M_recall>=0.949999999) & (M_recall >= 0.9500000001)])\n",
    "\n",
    "print('Males')\n",
    "print('Best f1: ', M_f1[M_index])\n",
    "print('Best precision: ', M_precision[M_index])\n",
    "print('Best threshold: ', M_thresholds[M_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M_Y_test_ready_pred_thresh = (M_model.predict_proba(M_X_test_selected)[:,1] >= 0.0018743522).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_ready_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1-Score: ', np.max(M_f1))\n",
    "print('Best precision: ', M_precision[np.argmax(M_f1)])\n",
    "print('Best recall: ', M_recall[np.argmax(M_f1)])\n",
    "print('Best threshold: ', M_thresholds[np.argmax(M_f1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Y_test_ready_pred_thresh = (M_model.predict_proba(M_X_test_selected)[:,1] >= 0.95).astype(bool)\n",
    "# F_Y_test_pred_thresh = (F_model.predict_proba(F_X_test)[:,1] >= 0.95).astype(bool)\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_ready, M_Y_test_ready_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "         dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "         dy_test_predict = model.predict(dx_test)\n",
    "         ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "         F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "         print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "         prevalence = np.sum(dy_test)/len(dy_test)\n",
    "         pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "         pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "         pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "         pyplot.xlabel('Sensitivity')\n",
    "         pyplot.ylabel('Positive Predicted Value')\n",
    "         pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "         pyplot.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "pr_f1_curve(M_xgb_selected, M_X_test_ready_selected, M_Y_test_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sfs_pure = load(\"M_sfs.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "plot_sfs(M_sfs_pure.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Number of variables', fontsize=20)\n",
    "plt.ylabel('f1 score', fontsize=20)\n",
    "plt.title('Sequential Floating Forward Selection - Males', fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig('M_sfs.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of countries\n",
    "country_list = ['Tanzania', 'Malawi','Zwaziland', 'Zambia']\n",
    "for name in country_list:\n",
    "    print('Male')\n",
    "    print('Country: ' + name)\n",
    "    print('prevalence train-sample: ' + '{:.1%}'.format(M_Y_train_entFe[name].sum()/len(M_Y_train_entFe[name])))\n",
    "    print('prevalence test-sample: ' + '{:.1%}'.format(M_Y_test_entFe[name].sum()/len(M_Y_test_entFe[name])))\n",
    "    print('prevalence validation-sample: ' + '{:.1%}'.format(CM_Y_test[name].sum()/len(CM_Y_test[name])))\n",
    "\n",
    "\n",
    "for name in country_list:\n",
    "    print('Female')\n",
    "    print('Country: ' + name)\n",
    "    print('prevalence train-sample: ' + '{:.1%}'.format(F_Y_train_entFe[name].sum()/len(F_Y_train_entFe[name])))\n",
    "    print('prevalence test-sample: ' + '{:.1%}'.format(F_Y_test_entFe[name].sum()/len(F_Y_test_entFe[name])))\n",
    "    print('prevalence validation-sample: ' + '{:.1%}'.format(CF_Y_test_entFe[name].sum()/len(CF_Y_test_entFe[name])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "# code for uploading pickled data\n",
    "\n",
    "# code for uploading pickled data\n",
    "# M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "# M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "M_X_train_ready = pickle.load(open(\"Train_samples\\M_X_train_ready.pkl\", 'rb'))\n",
    "M_Y_train_ready = pickle.load(open(\"Train_samples\\M_Y_train.pkl\", 'rb'))\n",
    "M_X_train_ready = pd.concat(M_X_train_ready.values(), join='inner', ignore_index=True)\n",
    "M_Y_train_ready = pd.concat(M_Y_train_ready.values(), join='inner', ignore_index=True)\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "M_model = load(\"xgb_selected\\M_xgb_selected_sample_data.joblib\")\n",
    "# F_model = load(\"xgb_entFe_pure_data/M_xgb_entFe_pure_data.joblib\")\n",
    "\n",
    "M_sfs_sample = SFS(M_model.best_estimator_, k_features=20, forward=True, floating=False, scoring='f1', verbose=1, cv=kfold, n_jobs=-1)\n",
    "# F_sfs = SFS(F_model.best_estimator_, k_features=30, forward=True, floating=True, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "\n",
    "M_sfs_sample.fit(M_X_train_ready, M_Y_train_ready)\n",
    "# F_sfs.fit(F_X_train_entFe, F_Y_train_entFe)\n",
    "\n",
    "dump(M_sfs_sample, 'M_sfs_sample.joblib')\n",
    "# dump(F_sfs, 'M_sfs_pure.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from joblib import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib.patches import PathPatch\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "# import file\n",
    "M_sfs_sample = load(\"M_sfs_sample.joblib\")\n",
    "# F_sfs_pure = load(\"F_sfs_pure.joblib\")\n",
    "\n",
    "M_dict_list = list(M_sfs_sample.get_metric_dict().values())\n",
    "# F_dict_list = list(F_sfs_pure.get_metric_dict().values())\n",
    "\n",
    "M_score = []\n",
    "# F_score = []\n",
    "\n",
    "for index in range(len(M_dict_list)):\n",
    "    M_score.append(M_dict_list[index]['avg_score'])\n",
    "#     F_score.append(F_dict_list[index]['avg_score'])\n",
    "\n",
    "def adjust_box_widths(g, fac):\n",
    "    \"\"\"\n",
    "    Adjust the withs of a seaborn-generated boxplot.\n",
    "    \"\"\"\n",
    "\n",
    "    # iterating through Axes instances\n",
    "    for ax in g.axes:\n",
    "\n",
    "        # iterating through axes artists:\n",
    "        for c in ax.get_children():\n",
    "\n",
    "            # searching for PathPatches\n",
    "            if isinstance(c, PathPatch):\n",
    "                # getting current width of box:\n",
    "                p = c.get_path()\n",
    "                verts = p.vertices\n",
    "                verts_sub = verts[:-1]\n",
    "                xmin = np.min(verts_sub[:, 0])\n",
    "                xmax = np.max(verts_sub[:, 0])\n",
    "                xmid = 0.5*(xmin+xmax)\n",
    "                xhalf = 0.5*(xmax - xmin)\n",
    "\n",
    "                # setting new width of box\n",
    "                xmin_new = xmid-fac*xhalf\n",
    "                xmax_new = xmid+fac*xhalf\n",
    "                verts_sub[verts_sub[:, 0] == xmin, 0] = xmin_new\n",
    "                verts_sub[verts_sub[:, 0] == xmax, 0] = xmax_new\n",
    "\n",
    "                # setting new width of median line\n",
    "                for l in ax.lines:\n",
    "                    if np.all(l.get_xdata() == [xmin, xmax]):\n",
    "                        l.set_xdata([xmin_new, xmax_new])\n",
    "\n",
    "\n",
    "y_loc = plticker.MultipleLocator(base=0.1)\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(2, 2, figsize=(22, 11))\n",
    "plt.subplots_adjust(wspace=0)\n",
    "sns.set(palette='deep')\n",
    "#sns.set_context(\"notebook\", font_scale=2, rc={\"lines.linewidth\": 4})\n",
    "sns.lineplot(x=list(range(1, 31)), y=M_score, palette=\"Blues\", ax = ax1)\n",
    "# sns.lineplot(x=list(range(1, 31)), y=F_score, palette=\"Blues\", ax = ax2)\n",
    "ax1.title.set_text('Males')\n",
    "ax2.title.set_text('Females')\n",
    "ax1.set_xlabel('Number of variables', fontsize=16)\n",
    "ax2.set_xlabel('Number of variables', fontsize=16)\n",
    "ax1.set_ylabel('f1 score')\n",
    "ax2.set_ylabel('')\n",
    "ax1.set(ylim=(0, 1))\n",
    "ax2.set(ylim=(0, 1))\n",
    "ax1.yaxis.set_major_locator(y_loc)\n",
    "ax2.yaxis.set_major_locator(y_loc)\n",
    "ax1.grid(b=True, which='major', axis='y')\n",
    "ax2.grid(b=True, which='major', axis='y')\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "fig.suptitle('Sequential floating forward selection', fontsize=24)\n",
    "\n",
    "adjust_box_widths(fig, 0.8)\n",
    "plt.savefig('sffs.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sfs_sample = load(\"M_sfs_sample.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(M_sfs_sample.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "plot_sfs(M_sfs_sample.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Number of variables', fontsize=20)\n",
    "plt.ylabel('f1 score', fontsize=20)\n",
    "plt.title('Sequential Floating Forward Selection - Males', fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig('M_sfs_sample.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = list(M_sfs_sample_pure.get_metric_dict().values())\n",
    "score = []\n",
    "for index in range(len(dict_list)):\n",
    "    score.append(dict_list[index]['avg_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(range(1, 31)), y=M_score, palette=\"Blues\", ax = ax1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
