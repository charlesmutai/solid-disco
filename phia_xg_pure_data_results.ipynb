{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_train_entFe = pickle.load(open(\"pure_data\\M_X_train_entFe.pkl\", 'rb'))\n",
    "M_Y_train_entFe = pickle.load(open(\"pure_data\\M_Y_train_entFe.pkl\", 'rb'))\n",
    "F_X_train_entFe = pickle.load(open(\"pure_data\\F_X_train_entFe.pkl\", 'rb'))\n",
    "F_Y_train_entFe = pickle.load(open(\"pure_data\\F_Y_train_entFe.pkl\", 'rb'))\n",
    "\n",
    "# M_X_train_entFe = pd.concat(M_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_train_entFe = pd.concat(M_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_X_train_entFe = pd.concat(F_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_train_entFe = pd.concat(F_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse'] \n",
    "  \n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "   \n",
    "     \n",
    "F_X_train_selected = F_X_train_entFe[F_selected_features]\n",
    "\n",
    "#================================================================================================================================\n",
    "# parameters space, models definition and random grid search\n",
    "#================================================================================================================================\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "scoring = ['f1', 'recall', 'precision']\n",
    "\n",
    "# XGBoost space\n",
    "params_xgb = {'learning_rate': np.linspace(0, 1, 11),\n",
    "              'min_split_loss': np.linspace(0, 1, 6),\n",
    "              'max_depth': np.linspace(2, 10, 5, dtype=int),\n",
    "              'min_child_weight': np.linspace(1, 20, 20, dtype=int),\n",
    "              'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "              'reg_alpha': np.linspace(0, 1, 11),\n",
    "              'scale_pos_weight': np.linspace(4, 50, 24, dtype=int),\n",
    "              'n_estimators': np.linspace(10, 450, 12, dtype=int),\n",
    "              'reg_lambda': np.linspace(0, 10, 11),\n",
    "             }\n",
    "\n",
    "M_xgb_selected = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "F_xgb_selected = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "M_xgb_selected.fit(M_X_train_selected, M_Y_train_entFe)\n",
    "dump(M_xgb_selected, \"xgb_selected\\M_xgb_selected_pure_data.joblib\")\n",
    "\n",
    "F_xgb_selected.fit(F_X_train_selected, F_Y_train_entFe)\n",
    "dump(F_xgb_selected, \"xgb_selected\\F_xgb_selected_pure_data.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import bisect \n",
    "from scipy.stats import mstats\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "# M_X_test_entFe = pd.concat(M_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_test_entFe = pd.concat(M_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_entFe = pickle.load(open(\"pure_data\\F_X_test_entFe.pkl\", 'rb'))\n",
    "F_Y_test_entFe = pickle.load(open(\"pure_data\\F_Y_test_entFe.pkl\", 'rb'))\n",
    "# F_X_test_entFe = pd.concat(F_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_test_entFe = pd.concat(F_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "# select features\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse']\n",
    "\n",
    "M_X_test_entFe = M_X_test_entFe[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    "  \n",
    "F_X_test_entFe = F_X_test_entFe[F_selected_features]\n",
    "\n",
    "M_model = load(\"xgb_selected\\M_xgb_selected_pure_data.joblib\")\n",
    "F_model = load(\"xgb_selected\\F_xgb_selected_pure_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "# M_X_test_entFe = pd.concat(M_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_test_entFe = pd.concat(M_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_entFe = pickle.load(open(\"pure_data\\F_X_test_entFe.pkl\", 'rb'))\n",
    "F_Y_test_entFe = pickle.load(open(\"pure_data\\F_Y_test_entFe.pkl\", 'rb'))\n",
    "# F_X_test_entFe = pd.concat(F_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_test_entFe = pd.concat(F_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_train_entFe = pickle.load(open(\"pure_data\\M_X_train_entFe.pkl\", 'rb'))\n",
    "M_Y_train_entFe = pickle.load(open(\"pure_data\\M_Y_train_entFe.pkl\", 'rb'))\n",
    "F_X_train_entFe = pickle.load(open(\"pure_data\\F_X_train_entFe.pkl\", 'rb'))\n",
    "F_Y_train_entFe = pickle.load(open(\"pure_data\\F_Y_train_entFe.pkl\", 'rb'))\n",
    "\n",
    "# M_X_train_entFe = pd.concat(M_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_train_entFe = pd.concat(M_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_X_train_entFe = pd.concat(F_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_train_entFe = pd.concat(F_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "M_selected_features = ['Age', 'Relationship with family head','Respondent live in household',\n",
    "                        'Known HIV status','Bought/sold sex in the past 12 months',\n",
    "                        'Condom was used at last paid sex in past 12 months','LAg: recent/long term infection',\n",
    "                        'CD4 category','on ART','ART initiated past 12 months those ever on ART',\n",
    "                        'last sex partner relations past 12 months','Sick to work last three months',\n",
    "                        'Ever attended school','Ever enrolled in school','Highest level of education',\n",
    "                        'Highest grade at that school level', 'Work for payment in last 12 months',\n",
    "                        'Ever married/lived together','Avoiding pregnancy','CFcumcision status',\n",
    "                        'Age at fFst sex', 'Ever sought TB treatment','Alcohol drink frequency',\n",
    "                        'Urban area indicator','Wealth quintile', 'Sexual intercourse in the past 12 months',\n",
    "                        'Ever had sexual intercourse']\n",
    "\n",
    "\n",
    "F_selected_features = ['Age', 'Relationship with family head', 'Respondent live in household',\n",
    "       'Sick to work last three months', 'Ever attended school',\n",
    "       'Ever enrolled in school', 'Highest level of education',\n",
    "       'Highest grade at that school level',\n",
    "       'Work for payment in last 12 months', 'Ever married/lived together',\n",
    "       'Number of pregnancies',\n",
    "       'Ever had a pregnancy that resulted in a live bFth',\n",
    "       'No. of childen given bFth since 2012', 'Pregnacy status now',\n",
    "       'Avoiding pregnancy', 'Age at fFst sex', 'Ever sought TB treatment',\n",
    "       'Alcohol drink frequency', 'Urban area indicator', 'Known HIV status',\n",
    "       'Wealth quintile', 'tested HIV at pregnancy',\n",
    "       'Delivered 12 months preceeding survey',\n",
    "       'Self-reported ARV status during pregnancy', 'Breastfed last child',\n",
    "       'Sexual intercourse past 12 months', 'Ever had sexual intercourse',\n",
    "       'Bought/sold sex in the past 12 months',\n",
    "       'Condom was used at last paid sex in past 12 months',\n",
    "       'last sex partner relations past 12 months',\n",
    "       'LAg: recent/long term infection', 'CD4 category', 'On ART',\n",
    "       'ART initiated past 12 months those ever on ART',\n",
    "       'Whether ARVs detected']\n",
    " \n",
    "\n",
    "\n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "F_X_train_selected = F_X_train_entFe[F_selected_features]\n",
    "M_X_test_selected = M_X_test_entFe[M_selected_features]\n",
    "F_X_test_selected = F_X_test_entFe[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_selected\\M_xgb_selected_pure_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_selected\\F_xgb_selected_pure_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_selected)\n",
    "\n",
    "print('Confusion matrix on the  M train dataset:', confusion_matrix(M_Y_train_entFe, M_Y_train_selected_pred))\n",
    "print('Average F1 score on the  M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_f1'][M_best_index]))\n",
    "print('CI F1 score on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_f1'][M_best_index]))\n",
    "print('Average Sensitivity on the M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_recall'][M_best_index]))\n",
    "print('CI Sensitivity on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_recall'][M_best_index]))\n",
    "print('Average Positive Predictive Value on the M train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_precision'][M_best_index]))\n",
    "print('CI Positive Predictive Value on the M train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_precision'][M_best_index]))\n",
    "print('Parameters', M_xgb_selected.best_estimator_)\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_entFe, F_Y_train_selected_pred))\n",
    "print('Average F1 score on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_f1'][F_best_index]))\n",
    "print('CI F1 score on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_f1'][F_best_index]))\n",
    "print('Average Sensitivity on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_recall'][F_best_index]))\n",
    "print('CI Sensitivity on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_recall'][F_best_index]))\n",
    "print('Average Positive Predictive Value on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_precision'][F_best_index]))\n",
    "print('CI Positive Predictive Value on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_precision'][F_best_index]))\n",
    "print('Parameters', F_xgb_selected.best_estimator_)\n",
    "\n",
    "from matplotlib import pyplot   \n",
    "M_Y_test_selected_pred = M_xgb_selected.predict(M_X_test_selected)\n",
    "F_Y_test_selected_pred = F_xgb_selected.predict(F_X_test_selected)\n",
    "\n",
    "\n",
    "\n",
    "print('Confusion matrix on the M test dataset:', confusion_matrix(M_Y_test_entFe, M_Y_test_selected_pred))\n",
    "print('F1 score on the M test dataset:', \"{:.1%}\".format(f1_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "\n",
    "print('Sensitivity on the M test dataset:', \"{:.1%}\".format(recall_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the M test dataset:', \"{:.1%}\".format(precision_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "print('Confusion matrix on the F test dataset:', confusion_matrix(F_Y_test_entFe, F_Y_test_selected_pred))\n",
    "print('F1 score on the F test dataset:', \"{:.1%}\".format(f1_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "print('Sensitivity on the F test dataset:', \"{:.1%}\".format(recall_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the F test dataset:', \"{:.1%}\".format(precision_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "     dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "     dy_test_predict = model.predict(dx_test)\n",
    "     ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "     F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "     print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "     prevalence = np.sum(dy_test)/len(dy_test)\n",
    "     pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "     pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "     pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "     pyplot.xlabel('Sensitivity')\n",
    "     pyplot.ylabel('Positive Predicted Value')\n",
    "     pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "     pyplot.show()\n",
    "\n",
    "pr_f1_curve(M_xgb_selected, M_X_test_selected, M_Y_test_entFe)\n",
    "pr_f1_curve(F_xgb_selected, F_X_test_selected, F_Y_test_entFe)\n",
    "\n",
    "# Explain model predictions using shapley value\n",
    "M_explainer = shap.TreeExplainer(M_xgb_selected.best_estimator_)\n",
    "M_shap_values = M_explainer.shap_values(M_X_train_selected)\n",
    "F_explainer = shap.TreeExplainer(F_xgb_selected.best_estimator_)\n",
    "F_shap_values = F_explainer.shap_values(F_X_train_selected)\n",
    "\n",
    "# Plot summary_plot\n",
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=32)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=20)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=25)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.savefig('/home/dr/phia data/M_shap.png')\n",
    "plt.savefig('/home/dr/phia data/F_shap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion matrix on the train dataset: [[30658    26]\n",
    " [    3  2864]]\n",
    "Average F1 score on the train sample 72.0%\n",
    "CI F1 score on the train sample 1.6%\n",
    "Average Sensitivity on the train sample 67.7%\n",
    "CI Sensitivity on the train sample 3.8%\n",
    "Average Positive Predictive Value on the train sample 76.9%\n",
    "CI Positive Predictive Value on the train sample 3.1%\n",
    "Parameters XGBClassifier(colsample_bytree=0.7, learning_rate=0.5, max_depth=10,\n",
    "              min_split_loss=0.4, missing=nan, n_estimators=210, nthread=1,\n",
    "              random_state=5, reg_alpha=0.6000000000000001, reg_lambda=1.0,\n",
    "              scale_pos_weight=4)\n",
    "Confusion matrix on the F train dataset: [[31261    15]\n",
    " [    2  4806]]\n",
    "Average F1 score on the F train sample 92.2%\n",
    "CI F1 score on the F train sample 1.7%\n",
    "Average Sensitivity on the F train sample 88.7%\n",
    "CI Sensitivity on the F train sample 3.8%\n",
    "Average Positive Predictive Value on the F train sample 96.0%\n",
    "CI Positive Predictive Value on the F train sample 1.4%\n",
    "Parameters XGBClassifier(colsample_bytree=0.7, learning_rate=0.5, max_depth=10,\n",
    "              min_split_loss=0.4, missing=nan, n_estimators=210, nthread=1,\n",
    "              random_state=5, reg_alpha=0.6000000000000001, reg_lambda=1.0,\n",
    "              scale_pos_weight=4)\n",
    "Confusion matrix on the test dataset: [[7601  102]\n",
    " [ 171  514]]\n",
    "F1 score on the test dataset: 79.0%\n",
    "Sensitivity on the test dataset: 75.0%\n",
    "Positive Predictive Value on the test dataset: 83.4%\n",
    "Confusion matrix on the F test dataset: [[7811   37]\n",
    " [ 124 1049]]\n",
    "F1 score on the F test dataset: 92.9%\n",
    "Sensitivity on the F test dataset: 89.4%\n",
    "Positive Predictive Value on the F test dataset: 96.6%\n",
    ": F1 score = 0.79 - Area under Curve = 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "M_model = load(\"xgb_selected\\M_xgb_selected_pure_data.joblib\")\n",
    "F_model = load(\"xgb_selected\\F_xgb_selected_pure_data.joblib\")\n",
    "M_precision, M_recall, M_thresholds = precision_recall_curve(M_Y_test_entFe, M_model.predict_proba(M_X_test_selected)[:,1])\n",
    "\n",
    "M_f1 = 2*M_recall*M_precision/(M_recall+M_precision)\n",
    "\n",
    "F_precision, F_recall, F_thresholds = precision_recall_curve(F_Y_test_entFe, F_model.predict_proba(F_X_test_selected)[:,1])\n",
    "\n",
    "F_f1 = 2*F_recall*F_precision/(F_recall+F_precision)\n",
    "\n",
    "\n",
    "# plot the precision-recall curves\n",
    "\n",
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"M_recall\"], precision[\"M_precision\"], color='gold', lw=2)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "              ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
    "                  ''.format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "              ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
    "                  ''.format(i, average_precision[i]))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "...     y_true, y_scores)\n",
    "precision\n",
    "array([0.66666667, 0.5       , 1.        , 1.        ])\n",
    ">>> recall\n",
    "array([1. , 0.5, 0.5, 0. ])\n",
    ">>> thresholds\n",
    "array([0.35, 0.4 , 0.8 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_index = np.argmax(M_precision[(M_recall>=0.949999999) & (M_recall >= 0.9500000001)])\n",
    "\n",
    "print('Males')\n",
    "print('Best f1: ', M_f1[M_index])\n",
    "print('Best precision: ', M_precision[M_index])\n",
    "print('Best threshold: ', M_thresholds[M_index])\n",
    "\n",
    "F_index = np.argmax(F_precision[(F_recall>=0.949999999) & (F_recall >= 0.9500000001)])\n",
    "\n",
    "print('Females')\n",
    "print('Best f1: ', F_f1[F_index])\n",
    "print('Best precision: ', F_precision[F_index])\n",
    "print('Best threshold: ', F_thresholds[F_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M_Y_test_pred_thresh = (M_model.predict_proba(M_X_test_selected)[:,1] >= 0.0018904804).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_entFe, M_Y_test_pred_thresh)\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model.predict_proba(F_X_test_selected)[:,1] >= 0.007321233).astype(bool)\n",
    "\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_entFe, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Y_test_pred_thresh = (M_model.predict_proba(M_X_test_selected)[:,1] >= 0.95).astype(bool)\n",
    "\n",
    "print('Males')\n",
    "confusion_matrix(M_Y_test_entFe, M_Y_test_pred_thresh)\n",
    "\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model.predict_proba(F_X_test_selected)[:,1] >= 0.95).astype(bool)\n",
    "\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_entFe, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1-Score: ', np.max(M_f1))\n",
    "print('Best precision: ', M_precision[np.argmax(M_f1)])\n",
    "print('Best recall: ', M_recall[np.argmax(M_f1)])\n",
    "print('Best threshold: ', M_thresholds[np.argmax(M_f1)])\n",
    "\n",
    "print('Best F1-Score: ', np.max(F_f1))\n",
    "print('Best precision: ', F_precision[np.argmax(F_f1)])\n",
    "print('Best recall: ', F_recall[np.argmax(F_f1)])\n",
    "print('Best threshold: ', F_thresholds[np.argmax(F_f1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "# code for uploading pickled data\n",
    "\n",
    "# code for uploading pickled data\n",
    "# M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "# M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "M_X_train_entFe = pickle.load(open(\"pure_data\\M_X_train_entFe.pkl\", 'rb'))\n",
    "M_Y_train_entFe = pickle.load(open(\"pure_data\\M_Y_train_entFe.pkl\", 'rb'))\n",
    "F_X_train_entFe = pickle.load(open(\"pure_data\\F_X_train_entFe.pkl\", 'rb'))\n",
    "F_Y_train_entFe = pickle.load(open(\"pure_data\\F_Y_train_entFe.pkl\", 'rb'))\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "M_model = load(\"xgb_selected\\M_xgb_selected_pure_data.joblib\")\n",
    "F_model = load(\"xgb_selected\\F_xgb_selected_pure_data.joblib\")\n",
    "\n",
    "M_sfs = SFS(M_model.best_estimator_, k_features=20, forward=True, floating=False, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "F_sfs = SFS(F_model.best_estimator_, k_features=25, forward=True, floating=True, scoring='f1', verbose=1, cv=0, n_jobs=-1)\n",
    "\n",
    "M_sfs.fit(M_X_train_entFe, M_Y_train_entFe)\n",
    "F_sfs.fit(F_X_train_entFe, F_Y_train_entFe)\n",
    "\n",
    "dump(M_sfs, 'M_sfs.joblib')\n",
    "dump(F_sfs, 'F_sfs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from joblib import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib.patches import PathPatch\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "# import file\n",
    "M_sfs_pure = load(\"M_sfs.joblib\")\n",
    "F_sfs_pure = load(\"F_sfs.joblib\")\n",
    "\n",
    "M_dict_list = list(M_sfs_pure.get_metric_dict().values())\n",
    "F_dict_list = list(F_sfs_pure.get_metric_dict().values())\n",
    "\n",
    "M_score = []\n",
    "F_score = []\n",
    "\n",
    "for index in range(len(M_dict_list)):\n",
    "    M_score.append(M_dict_list[index]['avg_score'])\n",
    "    F_score.append(F_dict_list[index]['avg_score'])\n",
    "\n",
    "def adjust_box_widths(g, fac):\n",
    "    \"\"\"\n",
    "    Adjust the withs of a seaborn-generated boxplot.\n",
    "    \"\"\"\n",
    "\n",
    "    # iterating through Axes instances\n",
    "    for ax in g.axes:\n",
    "\n",
    "        # iterating through axes artists:\n",
    "        for c in ax.get_children():\n",
    "\n",
    "            # searching for PathPatches\n",
    "            if isinstance(c, PathPatch):\n",
    "                # getting current width of box:\n",
    "                p = c.get_path()\n",
    "                verts = p.vertices\n",
    "                verts_sub = verts[:-1]\n",
    "                xmin = np.min(verts_sub[:, 0])\n",
    "                xmax = np.max(verts_sub[:, 0])\n",
    "                xmid = 0.5*(xmin+xmax)\n",
    "                xhalf = 0.5*(xmax - xmin)\n",
    "\n",
    "                # setting new width of box\n",
    "                xmin_new = xmid-fac*xhalf\n",
    "                xmax_new = xmid+fac*xhalf\n",
    "                verts_sub[verts_sub[:, 0] == xmin, 0] = xmin_new\n",
    "                verts_sub[verts_sub[:, 0] == xmax, 0] = xmax_new\n",
    "\n",
    "                # setting new width of median line\n",
    "                for l in ax.lines:\n",
    "                    if np.all(l.get_xdata() == [xmin, xmax]):\n",
    "                        l.set_xdata([xmin_new, xmax_new])\n",
    "\n",
    "\n",
    "y_loc = plticker.MultipleLocator(base=0.1)\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(2, 2, figsize=(22, 11))\n",
    "plt.subplots_adjust(wspace=0)\n",
    "sns.set(palette='deep')\n",
    "sns.set_context(\"notebook\", font_scale=2, rc={\"lines.linewidth\": 4})\n",
    "sns.lineplot(x=list(range(1, 31)), y=M_score, palette=\"Blues\", ax = ax1)\n",
    "sns.lineplot(x=list(range(1, 31)), y=F_score, palette=\"Blues\", ax = ax2)\n",
    "ax1.title.set_text('Males')\n",
    "ax2.title.set_text('Females')\n",
    "ax1.set_xlabel('Number of variables', fontsize=16)\n",
    "ax2.set_xlabel('Number of variables', fontsize=16)\n",
    "ax1.set_ylabel('f1 score')\n",
    "ax2.set_ylabel('')\n",
    "ax1.set(ylim=(0, 1))\n",
    "ax2.set(ylim=(0, 1))\n",
    "ax1.yaxis.set_major_locator(y_loc)\n",
    "ax2.yaxis.set_major_locator(y_loc)\n",
    "ax1.grid(b=True, which='major', axis='y')\n",
    "ax2.grid(b=True, which='major', axis='y')\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "fig.suptitle('Sequential floating forward selection', fontsize=24)\n",
    "\n",
    "adjust_box_widths(fig, 0.8)\n",
    "plt.savefig('sffs.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_sfs_pure.subsets_\n",
    "F_sfs_pure.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sfs_pure = load(\"M_sfs.joblib\")\n",
    "F_sfs_pure = load(\"F_sfs.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(M_sfs_pure.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0.3, 1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(F_sfs_pure.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(22, 11))\n",
    "\n",
    "plt.ylim([0.85, 1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "plot_sfs(M_sfs_pure.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(10, 6))\n",
    "\n",
    "plt.ylim([0.3, 1])\n",
    "plt.xlabel('Number of variables', fontsize=20)\n",
    "plt.ylabel('f1 score', fontsize=20)\n",
    "plt.title('SFFS - males', fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig('M_sfsfinal.jpg')\n",
    "\n",
    "plot_sfs(F_sfs_pure.get_metric_dict(),\n",
    "                kind='std_dev',\n",
    "                figsize=(10, 6))\n",
    "\n",
    "plt.ylim([0.85, 1])\n",
    "plt.xlabel('Number of variables', fontsize=20)\n",
    "plt.ylabel('f1 score', fontsize=20)\n",
    "plt.title('SFFS - females', fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig('F_sfsfinal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(range(1, 30)), y=M_score, palette=\"Blues\", ax = ax1)\n",
    "sns.lineplot(x=list(range(1, 30)), y=F_score, palette=\"Blues\", ax = ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_train_entFe = pickle.load(open(\"pure_data\\M_X_train_entFe.pkl\", 'rb'))\n",
    "M_Y_train_entFe = pickle.load(open(\"pure_data\\M_Y_train_entFe.pkl\", 'rb'))\n",
    "F_X_train_entFe = pickle.load(open(\"pure_data\\F_X_train_entFe.pkl\", 'rb'))\n",
    "F_Y_train_entFe = pickle.load(open(\"pure_data\\F_Y_train_entFe.pkl\", 'rb'))\n",
    "\n",
    "# M_X_train_entFe = pd.concat(M_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_train_entFe = pd.concat(M_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_X_train_entFe = pd.concat(F_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_train_entFe = pd.concat(F_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Ever enrolled in school',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Avoiding pregnancy',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Wealth quintile']  \n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile']    \n",
    "     \n",
    "F_X_train_selected = F_X_train_entFe[F_selected_features]\n",
    "\n",
    "#================================================================================================================================\n",
    "# parameters space, models definition and random grid search\n",
    "#================================================================================================================================\n",
    "\n",
    "# stratified k-fold and model initialization\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "scoring = ['f1', 'recall', 'precision']\n",
    "\n",
    "# XGBoost space\n",
    "params_xgb = {'learning_rate': np.linspace(0, 1, 11),\n",
    "              'min_split_loss': np.linspace(0, 1, 6),\n",
    "              'max_depth': np.linspace(2, 10, 5, dtype=int),\n",
    "              'min_child_weight': np.linspace(1, 20, 20, dtype=int),\n",
    "              'colsample_bytree': np.linspace(0.5, 1, 6),\n",
    "              'reg_alpha': np.linspace(0, 1, 11),\n",
    "              'scale_pos_weight': np.linspace(4, 50, 24, dtype=int),\n",
    "              'n_estimators': np.linspace(10, 450, 12, dtype=int),\n",
    "              'reg_lambda': np.linspace(0, 10, 11),\n",
    "             }\n",
    "\n",
    "M_xgb_selected_15 = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "F_xgb_selected_12 = RandomizedSearchCV(estimator=XGBClassifier(booster='gbtree',\n",
    "                                                                     objective='binary:logistic',\n",
    "                                                                     random_state=random_seed,\n",
    "                                                                     nthread=1,\n",
    "                                                                     verbosity=1),\n",
    "                                             param_distributions=params_xgb,\n",
    "                                             n_iter=250,\n",
    "                                             scoring=scoring,\n",
    "                                             cv=kfold,\n",
    "                                             n_jobs=-1,\n",
    "                                             random_state=random_seed,\n",
    "                                             verbose=2,\n",
    "                                             refit='f1')\n",
    "\n",
    "M_xgb_selected_15.fit(M_X_train_selected, M_Y_train_entFe)\n",
    "dump(M_xgb_selected_15, \"xgb_selected\\M_xgb_selected_15_data.joblib\")\n",
    "\n",
    "F_xgb_selected_12.fit(F_X_train_selected, F_Y_train_entFe)\n",
    "dump(F_xgb_selected_12, \"xgb_selected\\F_xgb_selected_12_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import bisect \n",
    "from scipy.stats import mstats\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "# M_X_test_entFe = pd.concat(M_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_test_entFe = pd.concat(M_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_entFe = pickle.load(open(\"pure_data\\F_X_test_entFe.pkl\", 'rb'))\n",
    "F_Y_test_entFe = pickle.load(open(\"pure_data\\F_Y_test_entFe.pkl\", 'rb'))\n",
    "# F_X_test_entFe = pd.concat(F_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_test_entFe = pd.concat(F_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Ever enrolled in school',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Avoiding pregnancy',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Wealth quintile']  \n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile']  \n",
    "F_X_test_entFe = F_X_test_entFe[F_selected_features]\n",
    "\n",
    "M_model_15 = load(\"xgb_selected\\M_xgb_selected_15_data.joblib\")\n",
    "F_model_12 = load(\"xgb_selected\\F_xgb_selected_12_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "\n",
    "# specifying constant parameters\n",
    "random_seed = 10\n",
    "\n",
    "# set working dFectory\n",
    "working_dFectory = r\"/home/dr/phia data\"\n",
    "os.chdF(working_dFectory)\n",
    "\n",
    "# code for uploading pickled data\n",
    "M_X_test_entFe = pickle.load(open(\"pure_data\\M_X_test_entFe.pkl\", 'rb'))\n",
    "M_Y_test_entFe = pickle.load(open(\"pure_data\\M_Y_test_entFe.pkl\", 'rb'))\n",
    "# M_X_test_entFe = pd.concat(M_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_test_entFe = pd.concat(M_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "F_X_test_entFe = pickle.load(open(\"pure_data\\F_X_test_entFe.pkl\", 'rb'))\n",
    "F_Y_test_entFe = pickle.load(open(\"pure_data\\F_Y_test_entFe.pkl\", 'rb'))\n",
    "# F_X_test_entFe = pd.concat(F_X_test_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_test_entFe = pd.concat(F_Y_test_entFe.values(), join='inner', ignore_index=True)\n",
    "\n",
    "M_X_train_entFe = pickle.load(open(\"pure_data\\M_X_train_entFe.pkl\", 'rb'))\n",
    "M_Y_train_entFe = pickle.load(open(\"pure_data\\M_Y_train_entFe.pkl\", 'rb'))\n",
    "F_X_train_entFe = pickle.load(open(\"pure_data\\F_X_train_entFe.pkl\", 'rb'))\n",
    "F_Y_train_entFe = pickle.load(open(\"pure_data\\F_Y_train_entFe.pkl\", 'rb'))\n",
    "\n",
    "# M_X_train_entFe = pd.concat(M_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# M_Y_train_entFe = pd.concat(M_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_X_train_entFe = pd.concat(F_X_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# F_Y_train_entFe = pd.concat(F_Y_train_entFe.values(), join='inner', ignore_index=True)\n",
    "# select features\n",
    "M_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Ever enrolled in school',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Avoiding pregnancy',\n",
    "   'CFcumcision status',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Alcohol drink frequency',\n",
    "   'Urban area indicator',\n",
    "   'Wealth quintile']  \n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "\n",
    "F_selected_features = ['Age',\n",
    "   'Relationship with family head',\n",
    "   'Highest level of education',\n",
    "   'Highest grade at that school level',\n",
    "   'Work for payment in last 12 months',\n",
    "   'Ever married/lived together',\n",
    "   'Number of pregnancies',\n",
    "   'No. of childen given bFth since 2012',\n",
    "   'Avoiding pregnancy',\n",
    "   'Age at fFst sex',\n",
    "   'Ever sought TB treatment',\n",
    "   'Known HIV status',\n",
    "   'Wealth quintile'] \n",
    "\n",
    "\n",
    "M_X_train_selected = M_X_train_entFe[M_selected_features]\n",
    "F_X_train_selected = F_X_train_entFe[F_selected_features]\n",
    "M_X_test_selected = M_X_test_entFe[M_selected_features]\n",
    "F_X_test_selected = F_X_test_entFe[F_selected_features]\n",
    "     \n",
    "M_xgb_selected = load(\"xgb_selected\\M_xgb_selected_15_data.joblib\")\n",
    "F_xgb_selected = load(\"xgb_selected\\F_xgb_selected_12_data.joblib\")\n",
    "\n",
    "M_best_index = M_xgb_selected.best_index_\n",
    "F_best_index = F_xgb_selected.best_index_\n",
    "\n",
    "M_Y_train_selected_pred = M_xgb_selected.predict(M_X_train_selected)\n",
    "# M_Y_train_selected_pred_thresh = (M_xgb_selected.predict_proba(M_X_train_selected)[:,1] >= 0.3).astype(bool) # set threshold as 0.3\n",
    "F_Y_train_selected_pred = F_xgb_selected.predict(F_X_train_selected)\n",
    "\n",
    "print('Confusion matrix on the train dataset:', confusion_matrix(M_Y_train_entFe, M_Y_train_selected_pred))\n",
    "print('Average F1 score on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_f1'][M_best_index]))\n",
    "print('CI F1 score on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_f1'][M_best_index]))\n",
    "print('Average Sensitivity on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_recall'][M_best_index]))\n",
    "print('CI Sensitivity on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_recall'][M_best_index]))\n",
    "print('Average Positive Predictive Value on the train sample', \"{:.1%}\".format(M_xgb_selected.cv_results_['mean_test_precision'][M_best_index]))\n",
    "print('CI Positive Predictive Value on the train sample', \"{:.1%}\".format(2*M_xgb_selected.cv_results_['std_test_precision'][M_best_index]))\n",
    "print('Parameters', M_xgb_selected.best_estimator_)\n",
    "\n",
    "print('Confusion matrix on the F train dataset:', confusion_matrix(F_Y_train_entFe, F_Y_train_selected_pred))\n",
    "print('Average F1 score on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_f1'][F_best_index]))\n",
    "print('CI F1 score on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_f1'][F_best_index]))\n",
    "print('Average Sensitivity on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_recall'][F_best_index]))\n",
    "print('CI Sensitivity on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_recall'][F_best_index]))\n",
    "print('Average Positive Predictive Value on the F train sample', \"{:.1%}\".format(F_xgb_selected.cv_results_['mean_test_precision'][F_best_index]))\n",
    "print('CI Positive Predictive Value on the F train sample', \"{:.1%}\".format(2*F_xgb_selected.cv_results_['std_test_precision'][F_best_index]))\n",
    "print('Parameters', F_xgb_selected.best_estimator_)\n",
    "     \n",
    "M_Y_test_selected_pred = M_xgb_selected.predict(M_X_test_selected)\n",
    "F_Y_test_selected_pred = F_xgb_selected.predict(F_X_test_selected)\n",
    "\n",
    "print('Confusion matrix on the test dataset:', confusion_matrix(M_Y_test_entFe, M_Y_test_selected_pred))\n",
    "print('F1 score on the test dataset:', \"{:.1%}\".format(f1_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "print('Sensitivity on the test dataset:', \"{:.1%}\".format(recall_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the test dataset:', \"{:.1%}\".format(precision_score(M_Y_test_entFe, M_Y_test_selected_pred)))\n",
    "\n",
    "print('Confusion matrix on the F test dataset:', confusion_matrix(F_Y_test_entFe, F_Y_test_selected_pred))\n",
    "print('F1 score on the F test dataset:', \"{:.1%}\".format(f1_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "print('Sensitivity on the F test dataset:', \"{:.1%}\".format(recall_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "print('Positive Predictive Value on the F test dataset:', \"{:.1%}\".format(precision_score(F_Y_test_entFe, F_Y_test_selected_pred)))\n",
    "\n",
    "\n",
    "def pr_f1_curve(model, dx_test, dy_test):\n",
    "     dy_test_predict_proba = model.predict_proba(dx_test)[:,1]\n",
    "     dy_test_predict = model.predict(dx_test)\n",
    "     ppv_curve, sensitivity_curve, _ = precision_recall_curve(dy_test, dy_test_predict_proba)\n",
    "     F1_score, AUC_score = f1_score(dy_test, dy_test_predict), auc(sensitivity_curve, ppv_curve)\n",
    "     print(': F1 score = %.2f - Area under Curve = %.2f' % (F1_score, AUC_score))\n",
    "     prevalence = np.sum(dy_test)/len(dy_test)\n",
    "     pyplot.plot([0, 1], [prevalence, prevalence], linestyle='--', label='Random Testing')\n",
    "     pyplot.plot(sensitivity_curve, ppv_curve, marker='.', label='Algorithmic Testing')\n",
    "     pyplot.plot(sensitivity_curve, 2*(sensitivity_curve*ppv_curve)/(sensitivity_curve+ppv_curve), marker='', label='F1')\n",
    "     pyplot.xlabel('Sensitivity')\n",
    "     pyplot.ylabel('Positive Predicted Value')\n",
    "     pyplot.legend(bbox_to_anchor=(0.45, 0.75))\n",
    "     pyplot.show()\n",
    "\n",
    "pr_f1_curve(M_xgb_selected, M_X_test_selected, M_Y_test_entFe)\n",
    "pr_f1_curve(F_xgb_selected, F_X_test_selected, F_Y_test_entFe)\n",
    "\n",
    "# Explain model predictions using shapley value\n",
    "M_explainer = shap.TreeExplainer(M_xgb_selected.best_estimator_)\n",
    "M_shap_values = M_explainer.shap_values(M_X_train_selected)\n",
    "F_explainer = shap.TreeExplainer(F_xgb_selected.best_estimator_)\n",
    "F_shap_values = F_explainer.shap_values(F_X_train_selected)\n",
    "\n",
    "# Plot summary_plot\n",
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=20)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=25)\n",
    "plt.savefig('M_shapfinal.jpg')\n",
    "plt.savefig('F_shapfinal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "M_shap = shap.summary_plot(M_shap_values, M_X_train_selected, max_display=20)\n",
    "F_shap = shap.summary_plot(F_shap_values, F_X_train_selected, max_display=25)\n",
    "plt.savefig('M_shap.jpg')\n",
    "plt.savefig('F_shap.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_model_15 = load(\"xgb_selected\\M_xgb_selected_15_data.joblib\")\n",
    "F_model_12 = load(\"xgb_selected\\F_xgb_selected_12_data.joblib\")\n",
    "M_precision, M_recall, M_thresholds = precision_recall_curve(M_Y_test_entFe, M_model_15.predict_proba(M_X_test_selected)[:,1])\n",
    "\n",
    "M_f1 = 2*M_recall*M_precision/(M_recall+M_precision)\n",
    "\n",
    "F_precision, F_recall, F_thresholds = precision_recall_curve(F_Y_test_entFe, F_model_12.predict_proba(F_X_test_selected)[:,1])\n",
    "\n",
    "F_f1 = 2*F_recall*F_precision/(F_recall+F_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_index = np.argmax(M_precision[(M_recall>=0.949999999) & (M_recall >= 0.9500000001)])\n",
    "\n",
    "print('Males')\n",
    "print('Best f1: ', M_f1[M_index])\n",
    "print('Best precision: ', M_precision[M_index])\n",
    "print('Best threshold: ', M_thresholds[M_index])\n",
    "\n",
    "F_index = np.argmax(F_precision[(F_recall>=0.899999999) & (F_recall >= 0.9000000001)])\n",
    "\n",
    "print('Females')\n",
    "print('Best f1: ', F_f1[F_index])\n",
    "print('Best precision: ', F_precision[F_index])\n",
    "print('Best threshold: ', F_thresholds[F_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# M_Y_test_pred_thresh = (M_model_15.predict_proba(M_X_test_selected)[:,1] >= 0.002331057).astype(bool)\n",
    "\n",
    "# print('Males')\n",
    "# confusion_matrix(M_Y_test_entFe, M_Y_test_pred_thresh)\n",
    "\n",
    "F_Y_test_pred_thresh = (F_model_12.predict_proba(F_X_test_selected)[:,1] >= 0.12806101).astype(bool)\n",
    "\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_entFe, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_Y_test_pred_thresh = (M_model_15.predict_proba(M_X_test_selected)[:,1] >= 0.90).astype(bool)\n",
    "F_Y_test_pred_thresh = (F_model_12.predict_proba(F_X_test_selected)[:,1] >= 0.90).astype(bool)\n",
    "# print('Males')\n",
    "# confusion_matrix(M_Y_test_entFe, M_Y_test_pred_thresh)\n",
    "print('Females')\n",
    "confusion_matrix(F_Y_test_entFe, F_Y_test_pred_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best F1-Score: ', np.max(M_f1))\n",
    "print('Best precision: ', M_precision[np.argmax(M_f1)])\n",
    "print('Best recall: ', M_recall[np.argmax(M_f1)])\n",
    "print('Best threshold: ', M_thresholds[np.argmax(M_f1)])\n",
    "\n",
    "print('Best F1-Score: ', np.max(F_f1))\n",
    "print('Best precision: ', F_precision[np.argmax(F_f1)])\n",
    "print('Best recall: ', F_recall[np.argmax(F_f1)])\n",
    "print('Best threshold: ', F_thresholds[np.argmax(F_f1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
